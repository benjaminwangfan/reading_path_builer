{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d074c7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lxml import html\n",
    "\n",
    "from mdict_analysis.readmdict import MDX\n",
    "\n",
    "mdx = MDX(\"The BNC-COCA Lists/the-bnc-coca-lists.mdx\")\n",
    "words = []\n",
    "labels = []\n",
    "labels_preq = []\n",
    "total_freqs = []\n",
    "\n",
    "for key, value in mdx.items():\n",
    "    word = key.decode()\n",
    "    words.append(word)\n",
    "    page = value.decode(\"utf-8\")\n",
    "    page_tree = html.fromstring(page)\n",
    "    try:\n",
    "        label = page_tree.xpath(\"//h1/span[@class='label']\")[0].text\n",
    "    except:\n",
    "        label = None\n",
    "    labels.append(label)\n",
    "    try:\n",
    "        label_freq = page_tree.xpath(\"//h1/span[contains(@class, 'freq-level')]\")[\n",
    "            0\n",
    "        ].text\n",
    "    except:\n",
    "        label_freq = None\n",
    "    labels_preq.append(label_freq)\n",
    "    try:\n",
    "        total_freq = page_tree.xpath(\"//p[@class='word-frequency']\")[0].text.replace(\n",
    "            \"Total Frequency: \", \"\"\n",
    "        )\n",
    "    except:\n",
    "        total_freq = None\n",
    "    total_freqs.append(total_freq)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    dict(\n",
    "        word=words,\n",
    "        label=labels,\n",
    "        label_freq=labels_preq,\n",
    "        total_freq=total_freqs,\n",
    "    )\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca003ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_trf\", disable=[\"parser\", \"ner\"])\n",
    "word_freq_df = pd.read_csv(\"bnc_coca_word_freq.csv\")\n",
    "\n",
    "\n",
    "def process_tokens(doc):\n",
    "    return [\n",
    "        token.lemma_.lower()\n",
    "        for token in doc\n",
    "        if not token.is_stop\n",
    "        and not token.is_punct\n",
    "        and token.is_alpha\n",
    "        and len(token.text) > 2\n",
    "        and token.pos_ != \"PROPN\"\n",
    "    ]\n",
    "\n",
    "\n",
    "def process_tokens_and_info(doc):\n",
    "    return [\n",
    "        (token.lemma_.lower(), token.pos_)\n",
    "        for token in doc\n",
    "        if not token.is_stop\n",
    "        and not token.is_punct\n",
    "        and token.is_alpha\n",
    "        and len(token.text) > 2\n",
    "        and token.pos_ != \"PROPN\"\n",
    "    ]\n",
    "\n",
    "\n",
    "def df_to_normalized_vector(df, max_k=30):\n",
    "    \"\"\"\n",
    "    将词汇分布DataFrame转为归一化向量\n",
    "    :param df: 输入DataFrame (index='1k','2k'...; columns='count')\n",
    "    :param max_k: 最大频率区间 (默认到30k)\n",
    "    :return: 归一化向量 (numpy array)\n",
    "    \"\"\"\n",
    "    # 创建全0向量 (长度=max_k)\n",
    "    vector = np.zeros(max_k)\n",
    "\n",
    "    # 填充有效数据\n",
    "    for label, count in df[\"count\"].items():\n",
    "        k_val = int(label.replace(\"k\", \"\"))  # 提取数字部分\n",
    "        if 1 <= k_val <= max_k:\n",
    "            vector[k_val - 1] = count  # 1k对应索引0, 2k对应索引1...\n",
    "\n",
    "    # 归一化处理\n",
    "    return vector / vector.sum()\n",
    "\n",
    "\n",
    "def get_word_freq_ranking(file_path):\n",
    "    doc = nlp(Path(file_path).read_text())\n",
    "    tokens = process_tokens(doc)\n",
    "    tokens_df = pd.DataFrame({\"word\": tokens})\n",
    "    word_counts = tokens_df[\"word\"].value_counts().reset_index()\n",
    "    word_counts.columns = [\"word\", \"count\"]  # 重命名列\n",
    "    word_counts = word_counts.merge(word_freq_df, on=\"word\")\n",
    "    return (\n",
    "        word_counts.groupby(\"label\")\n",
    "        .agg({\"label\": \"count\"})\n",
    "        .sort_index(key=lambda x: x.str.replace(\"k\", \"\").astype(int))\n",
    "        .rename(columns={\"label\": \"count\"})\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90eb98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = Path(\"book_sentence\").glob(\"*.txt\")\n",
    "vectors = []\n",
    "for book in books:\n",
    "    result = df_to_normalized_vector(get_word_freq_ranking(book))\n",
    "    vectors.append(result)\n",
    "    print(book.stem)\n",
    "\n",
    "book_vocab_vectors = pd.DataFrame(\n",
    "    data=dict(\n",
    "        book=[i.stem for i in Path(\"book_sentence\").glob(\"*.txt\")], vector=vectors\n",
    "    ),\n",
    "    columns=pd.Index([\"book\", \"vector\"], dtype=\"object\"),\n",
    ")\n",
    "\n",
    "book_vocab_vectors[\"vector\"] = book_vocab_vectors[\"vector\"].apply(lambda x: x.tolist())\n",
    "book_vocab_vectors.to_csv(\"book_vocab_vectors.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57fd41d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for book in Path(\"book_sentence\").glob(\"*.txt\"):\n",
    "    doc = nlp(book.read_text())\n",
    "    tokens_info = process_tokens_and_info(doc)\n",
    "    df = pd.DataFrame(tokens_info, columns=pd.Index([\"word\", \"pos\"]))\n",
    "    words = df[\"word\"].unique()\n",
    "    df.pivot_table(index=\"word\", columns=\"pos\", aggfunc=\"size\").fillna(0).astype(\n",
    "        int\n",
    "    ).loc[words].to_csv(Path(\"book_vocab\") / (book.stem + \".csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9bad58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot_table(index=\"word\", columns=\"pos\", aggfunc=\"size\").fillna(0).astype(int).loc[\n",
    "    \"ability\", \"NOUN\"\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

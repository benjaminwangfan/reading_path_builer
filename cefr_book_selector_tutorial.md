# åˆ†å±‚è´ªå¿ƒç®—æ³•ï¼šæ„å»ºæ¸è¿›å¼è‹±è¯­é˜…è¯»è·¯å¾„çš„å®Œæ•´æŒ‡å—

åœ¨è‹±è¯­å­¦ä¹ ä¸­ï¼Œé€‰æ‹©é€‚åˆå½“å‰æ°´å¹³çš„é˜…è¯»ææ–™æ˜¯å…³é”®æŒ‘æˆ˜ä¹‹ä¸€ã€‚å¤ªç®€å•çš„å†…å®¹æ— æ³•æå‡æ°´å¹³ï¼Œå¤ªéš¾çš„å†…å®¹åˆä¼šè®©äººå¤±å»ä¿¡å¿ƒã€‚ä»Šå¤©ï¼Œæˆ‘ä»¬å°†é€šè¿‡ä¸€ä¸ª**åˆ†å±‚è´ªå¿ƒç®—æ³•**æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå¸®åŠ©å­¦ä¹ è€…æ„å»ºä¸€æ¡**æ¸è¿›å¼**çš„é˜…è¯»è·¯å¾„ã€‚

æœ¬æ•™ç¨‹å°†å¸¦ä½ ä»é›¶å¼€å§‹ç†è§£è¿™ä¸ªç®—æ³•ï¼Œå³ä½¿ä½ å¯¹è´ªå¿ƒç®—æ³•ä¸å¤ªç†Ÿæ‚‰ä¹Ÿæ²¡å…³ç³»ï¼æˆ‘ä»¬å°†åƒå‰¥æ´‹è‘±ä¸€æ ·ï¼Œä¸€å±‚å±‚æ­å¼€è¿™ä¸ªå®ç”¨å·¥å…·çš„ç¥ç§˜é¢çº±ã€‚

## ä¸ºä»€ä¹ˆéœ€è¦è¿™ä¸ªç®—æ³•ï¼Ÿ

æƒ³è±¡ä¸€ä¸‹ï¼Œä½ æ˜¯ä¸€ä½è‹±è¯­å­¦ä¹ è€…ï¼Œç›®æ ‡æ˜¯è¾¾åˆ°C1æ°´å¹³ã€‚ä½ æœ‰æ•°ç™¾æœ¬ä¹¦å¯ä¾›é€‰æ‹©ï¼Œä½†ï¼š

- ä½ ä¸çŸ¥é“å“ªäº›ä¹¦é€‚åˆä½ çš„å½“å‰æ°´å¹³
- è¯»å¤ªç®€å•çš„ä¹¦è¿›æ­¥æ…¢
- è¯»å¤ªéš¾çš„ä¹¦å®¹æ˜“æ”¾å¼ƒ
- ä½ éœ€è¦ä¸€æ¡**å¾ªåºæ¸è¿›**çš„è·¯å¾„

è¿™æ­£æ˜¯æˆ‘ä»¬ä»Šå¤©è¦è§£å†³çš„é—®é¢˜ï¼æˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªç®—æ³•ï¼Œèƒ½æ ¹æ®**CEFRæ ‡å‡†**ï¼ˆæ¬§æ´²è¯­è¨€å…±åŒå‚è€ƒæ¡†æ¶ï¼‰è‡ªåŠ¨æ¨èæœ€é€‚åˆä½ å½“å‰æ°´å¹³çš„é˜…è¯»ææ–™ï¼Œå¹¶è§„åˆ’å‡ºä¸€æ¡ä»A1åˆ°C1çš„å¹³æ»‘å­¦ä¹ è·¯å¾„ã€‚

## ç®—æ³•æ ¸å¿ƒæ€æƒ³ï¼šåˆ†è€Œæ²»ä¹‹ + è´ªå¿ƒé€‰æ‹©

æˆ‘ä»¬çš„ç®—æ³•åŸºäºä¸‰ä¸ªæ ¸å¿ƒæ€æƒ³ï¼š

1. **åˆ†å±‚å¤„ç†**ï¼šå°†å¤æ‚çš„å¤šç›®æ ‡é—®é¢˜åˆ†è§£ä¸ºæŒ‰éš¾åº¦ç­‰çº§çš„å­é—®é¢˜
2. **è´ªå¿ƒé€‰æ‹©**ï¼šåœ¨æ¯ä¸ªç­‰çº§å†…ï¼Œæ¯æ¬¡éƒ½é€‰æ‹©"å½“å‰æœ€ä¼˜"çš„ä¹¦ç±
3. **é€‚åˆåº¦åˆ†æ**ï¼šå¼•å…¥ä¹¦ç±å¯¹ç‰¹å®šç­‰çº§çš„"é€‚åˆåº¦"è¯„ä¼°ï¼Œæ›´ç²¾å‡†åœ°åŒ¹é…å­¦ä¹ éœ€æ±‚

è¿™ç§ç­–ç•¥ç±»ä¼¼äºç™»å±±ï¼šå…ˆä¸“æ³¨ç™»ä¸Šä¸€ä¸ªå°å±±å³°ï¼ˆA1ï¼‰ï¼Œç„¶åä»¥æ­¤ä¸ºåŸºç¡€æ”€ç™»ä¸‹ä¸€ä¸ªï¼ˆA2ï¼‰ï¼Œä¾æ­¤ç±»æ¨ï¼Œç›´åˆ°è¾¾åˆ°æœ€ç»ˆç›®æ ‡ï¼ˆC1ï¼‰ã€‚

## ç¬¬ä¸€æ­¥ï¼šç†è§£é—®é¢˜åŸŸ

åœ¨æ·±å…¥ä»£ç å‰ï¼Œè®©æˆ‘ä»¬å…ˆæ˜ç¡®å‡ ä¸ªå…³é”®æ¦‚å¿µï¼š

- **CEFRç­‰çº§**ï¼šA1ï¼ˆåŸºç¡€ï¼‰ã€A2ï¼ˆåˆçº§ï¼‰ã€B1ï¼ˆä¸­çº§ï¼‰ã€B2ï¼ˆä¸­é«˜çº§ï¼‰ã€C1ï¼ˆé«˜çº§ï¼‰
- **è¯æ±‡çº§åˆ«**ï¼šæ¯ä¸ªå•è¯éƒ½æœ‰å…¶CEFRçº§åˆ«
- **ä¹¦ç±è¯æ±‡åˆ†å¸ƒ**ï¼šæ¯æœ¬ä¹¦åŒ…å«ä¸åŒçº§åˆ«çš„è¯æ±‡
- **è¶…çº²è¯æ±‡ï¼ˆBEYONDï¼‰**ï¼šä¹¦ä¸­å‡ºç°ä½†æœªåœ¨å­¦ä¹ è¯è¡¨ä¸­å®šä¹‰çš„è¯æ±‡

æˆ‘ä»¬çš„ç›®æ ‡æ˜¯ï¼š**ä¸ºå­¦ä¹ è€…é€‰æ‹©ä¸€ç»„ä¹¦ç±ï¼Œä½¿å…¶èƒ½å¤Ÿå¹³æ»‘åœ°ä»A1è¿‡æ¸¡åˆ°C1æ°´å¹³ï¼Œæ¯æœ¬ä¹¦éƒ½ç•¥é«˜äºå½“å‰æ°´å¹³ä½†åˆä¸è‡³äºå¤ªéš¾**ã€‚

## ç¬¬äºŒæ­¥ï¼šæ•°æ®ç»“æ„å‡†å¤‡

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ä¸¤ç±»æ•°æ®ï¼š

1. **ä¹¦ç±è¯æ±‡æ•°æ®**ï¼šæ¯æœ¬ä¹¦åŒ…å«å“ªäº›å•è¯
2. **è¯æ±‡çº§åˆ«æ•°æ®**ï¼šæ¯ä¸ªå•è¯å±äºå“ªä¸ªCEFRçº§åˆ«

```python
# ç¤ºä¾‹æ•°æ®ç»“æ„
books_vocab = {
    "book_1": {"hello", "world", "cat", "dog"},
    "book_2": {"advanced", "vocabulary", "cat", "sun"},
    "book_3": {"sophisticated", "phenomenon", "analysis", "hello"},
    # ... æ›´å¤šä¹¦ç±
}

vocab_levels = {
    "hello": "A1",
    "world": "A1",
    "cat": "A1",
    "dog": "A1",
    "sun": "A2",
    "analysis": "B1",
    "advanced": "B2",
    "vocabulary": "B2",
    "sophisticated": "C1",
    "phenomenon": "C1",
    # ... æ›´å¤šå•è¯
}
```

> ğŸ’¡ **å°çŸ¥è¯†**ï¼šåœ¨çœŸå®åœºæ™¯ä¸­ï¼Œvocab_levelsä¼šåŒ…å«æ•°åƒä¸ªå•è¯åŠå…¶å¯¹åº”çš„CEFRçº§åˆ«ï¼Œä»A1åŸºç¡€è¯æ±‡åˆ°C1é«˜çº§è¯æ±‡ã€‚ä¹¦ä¸­å‡ºç°ä½†æœªåœ¨vocab_levelsä¸­å®šä¹‰çš„è¯æ±‡å°†è¢«æ ‡è®°ä¸º"BEYOND"ï¼ˆè¶…çº²è¯æ±‡ï¼‰ã€‚

## ç¬¬ä¸‰æ­¥ï¼šåˆå§‹åŒ–ç®—æ³•ç±»

è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªç±»æ¥å°è£…æˆ‘ä»¬çš„ç®—æ³•é€»è¾‘ï¼š

```python
from collections import defaultdict
from typing import Dict, List, Set, Tuple
import numpy as np

class LayeredCEFRBookSelector:
    def __init__(self, books_vocab: Dict[str, Set[str]], vocab_levels: Dict[str, str]):
        """
        ç®—æ³•åˆå§‹åŒ–ï¼šæ•°æ®é¢„å¤„ç†å’Œç»Ÿè®¡åˆ†æ
        
        Args:
            books_vocab: {book_id: set(æ‰€æœ‰è¯æ±‡)} - æ¯æœ¬ä¹¦çš„å®é™…è¯æ±‡é›†åˆ
            vocab_levels: {word: level} - å­¦ä¹ è¯è¡¨ï¼ˆåªåŒ…å« A1~C1 çš„è¯åŠå…¶ç­‰çº§ï¼‰
        """
        # å¯å‘å¼æƒé‡ï¼šä½ç­‰çº§è¯æ±‡å¯¹åˆå­¦è€…ä»·å€¼æ›´é«˜
        self.level_weights = {
            "A1": 1.5,
            "A2": 1.3,
            "B1": 1.1,
            "B2": 1.0,
            "C1": 0.9,
        }

        # å­¦ä¹ ç›®æ ‡ç­‰çº§
        self.learning_levels = ["A1", "A2", "B1", "B2", "C1"]
        # å®Œæ•´ç­‰çº§ï¼ˆç”¨äºè¾“å‡ºï¼‰
        self.all_levels = self.learning_levels + ["BEYOND"]

        self.books_vocab = books_vocab
        self.vocab_levels = vocab_levels  # åªåŒ…å« A1~C1 çš„è¯

        # ä»å­¦ä¹ è¯è¡¨ä¸­æ„å»º level_vocabï¼ˆåªåŒ…å«å·²çŸ¥ç­‰çº§çš„è¯ï¼‰
        self.level_vocab = self._group_vocab_by_level()

        # é¢„è®¡ç®—ä¹¦ç±ç»Ÿè®¡ä¿¡æ¯
        self.book_stats = self._calculate_layered_book_stats()
```

### ä¸ºä»€ä¹ˆéœ€è¦é¢„å¤„ç†ï¼Ÿ

é¢„å¤„ç†æ˜¯ç®—æ³•é«˜æ•ˆè¿è¡Œçš„å…³é”®ã€‚æƒ³è±¡ä¸€ä¸‹ï¼Œå¦‚æœä½ æ¯æ¬¡éƒ½è¦æ£€æŸ¥ä¸€æœ¬æœ‰5000ä¸ªå•è¯çš„ä¹¦ä¸­æœ‰å¤šå°‘æ˜¯A1çº§åˆ«çš„ï¼Œè€Œä½ æœ‰400æœ¬ä¹¦ï¼Œé‚£å°†æ˜¯å¤šä¹ˆè€—æ—¶ï¼

é€šè¿‡é¢„å¤„ç†ï¼Œæˆ‘ä»¬å°†ï¼š

- å°†è¯æ±‡æŒ‰çº§åˆ«åˆ†ç»„ï¼ˆO(n)æ—¶é—´å¤æ‚åº¦ï¼‰
- é¢„è®¡ç®—æ¯æœ¬ä¹¦çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆO(ä¹¦ç±æ•°Ã—å¹³å‡å•è¯æ•°)ï¼‰

è¿™æ ·ï¼Œåœ¨åç»­é€‰æ‹©è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥**ç«‹å³æŸ¥è¯¢**è¿™äº›ä¿¡æ¯ï¼Œè€Œä¸æ˜¯é‡å¤è®¡ç®—ã€‚

## ç¬¬å››æ­¥ï¼šæ•°æ®é¢„å¤„ç†è¯¦è§£

è®©æˆ‘ä»¬æ·±å…¥ç ”ç©¶ `_group_vocab_by_level()` æ–¹æ³•ï¼š

```python
def _group_vocab_by_level(self) -> Dict[str, Set[str]]:
    """
    ä»…å¯¹ vocab_levels ä¸­çš„è¯æŒ‰ç­‰çº§åˆ†ç»„
    æ³¨æ„ï¼šä¸åŒ…å«ä¹¦ä¸­å‡ºç°ä½†æœªåœ¨ vocab_levels ä¸­å®šä¹‰çš„è¯
    
    è¿”å›ç¤ºä¾‹:
    {
        "A1": {"hello", "cat", ...},
        "A2": {"world", "dog", ...},
        "B1": {"analysis", ...},
        "B2": {"advanced", "vocabulary", ...},
        "C1": {"sophisticated", "phenomenon", ...}
    }
    """
    level_vocab = defaultdict(set)
    for word, level in self.vocab_levels.items():
        if level in self.learning_levels:
            level_vocab[level].add(word)

    print("ğŸ“š å­¦ä¹ è¯è¡¨åˆ†å±‚ç»Ÿè®¡ï¼ˆæ¥è‡ª vocab_levelsï¼‰:")
    for level in self.learning_levels:
        count = len(level_vocab[level])
        print(f"  {level}: {count}è¯")

    return dict(level_vocab)
```

è¿™ä¸ªæ–¹æ³•éå¸¸ç®€å•ä½†æå…¶é‡è¦ã€‚å®ƒå°†æ‰å¹³çš„è¯æ±‡åˆ—è¡¨è½¬æ¢ä¸ºæŒ‰çº§åˆ«ç»„ç»‡çš„ç»“æ„ï¼Œè®©æˆ‘ä»¬å¯ä»¥å¿«é€Ÿå›ç­”"å“ªäº›å•è¯å±äºA1çº§åˆ«ï¼Ÿ"è¿™æ ·çš„é—®é¢˜ã€‚

### å®é™…æ•ˆæœæ¼”ç¤º

å‡è®¾æˆ‘ä»¬æœ‰ä»¥ä¸‹è¯æ±‡æ•°æ®ï¼š

```python
vocab_levels = {
    "hello": "A1", "world": "A1", "cat": "A1", 
    "sun": "A2", "moon": "A2", 
    "analysis": "B1", "structure": "B1",
    "advanced": "B2", "vocabulary": "B2",
    "sophisticated": "C1", "phenomenon": "C1"
}
```

ç»è¿‡ `_group_vocab_by_level()` å¤„ç†åï¼Œæˆ‘ä»¬ä¼šå¾—åˆ°ï¼š

```python
{
    "A1": {"hello", "world", "cat"},
    "A2": {"sun", "moon"},
    "B1": {"analysis", "structure"},
    "B2": {"advanced", "vocabulary"},
    "C1": {"sophisticated", "phenomenon"}
}
```

ç°åœ¨ï¼Œå¦‚æœæˆ‘ä»¬æƒ³çŸ¥é“æ‰€æœ‰A1çº§åˆ«çš„å•è¯ï¼Œåªéœ€è®¿é—® `level_vocab["A1"]`ï¼Œæ—¶é—´å¤æ‚åº¦ä¸ºO(1)ï¼

## ç¬¬äº”æ­¥ï¼šä¹¦ç±ç»Ÿè®¡ä¿¡æ¯è®¡ç®—

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è®¡ç®—æ¯æœ¬ä¹¦çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯ï¼š

```python
def _calculate_layered_book_stats(self) -> Dict[str, Dict]:
    """
    ç»Ÿè®¡æ¯æœ¬ä¹¦çš„å¤šç»´ç‰¹å¾

    å…³é”®é€»è¾‘ï¼š
    - unknown_words = ä¹¦ä¸­è¯æ±‡ - vocab_levels.keys()ï¼ˆå®Œå…¨æœªå®šä¹‰çš„è¯ï¼‰
    - æ‰€æœ‰æ¯”ä¾‹è®¡ç®—åŸºäºæ€»è¯æ±‡æ•°ï¼ˆå« B2/C1 å’Œ unknownï¼‰
    - æ–°å¢ suitability_for[level]ï¼šè¯„ä¼°è¯¥ä¹¦å¯¹æŸç­‰çº§çš„é€‚åˆåº¦
    
    è¿”å›ç¤ºä¾‹:
    {
        "book_1": {
            "total_words": 5000,
            "level_counts": {"A1": 100, "A2": 2000, ...},
            "level_ratios": {"A1": 0.02, "A2": 0.4, ...},
            "unknown_words": {"quantum", "relativity"},
            "difficulty_score": 2.3,
            "learning_value": 1.8,
            "suitability_for": {"A1": 0.6, "A2": 0.7, ...}
        },
        ...
    }
    """
    stats = {}
    
    # æ„å»ºæ‰€æœ‰å·²çŸ¥å­¦ä¹ è¯æ±‡çš„é›†åˆï¼ˆç”¨äºè¯†åˆ« unknownï¼‰
    known_learning_words = set(self.vocab_levels.keys())
    
    for book_id, vocab in self.books_vocab.items():
        book_stats = {
            "total_words": len(vocab),
            "level_words": {},  # æŒ‰ç­‰çº§åˆ†ç»„çš„è¯æ±‡é›†åˆ
            "level_counts": {},  # å„ç­‰çº§è¯æ±‡æ•°é‡
            "level_ratios": {},  # å„ç­‰çº§è¯æ±‡æ¯”ä¾‹
            "unknown_words": set(),  # è¶…çº²è¯ = æœªåœ¨å­¦ä¹ è¯è¡¨ä¸­å®šä¹‰çš„è¯
            "difficulty_score": 0,  # éš¾åº¦åˆ†æ•°ï¼ˆåŠ æƒå¹³å‡ï¼‰
            "learning_value": 0,  # å­¦ä¹ ä»·å€¼åˆ†æ•°
            "suitability_for": {},  # æ–°å¢ï¼šå¯¹æ¯ä¸ªç­‰çº§çš„é€‚åˆåº¦
        }
        
        # ç»Ÿè®¡ A1~C1 å„ç­‰çº§è¯æ±‡
        learning_words_count = 0
        for level in self.learning_levels:
            level_set = self.level_vocab.get(level, set())
            words_in_level = vocab & level_set
            book_stats["level_words"][level] = words_in_level
            count = len(words_in_level)
            book_stats["level_counts"][level] = count
            book_stats["level_ratios"][level] = count / len(vocab) if vocab else 0
            learning_words_count += count
        
        # ğŸŒŸ æ ¸å¿ƒï¼šunknown_words = ä¹¦ä¸­å‡ºç°ä½†æœªåœ¨å­¦ä¹ è¯è¡¨ä¸­çš„è¯
        unknown_words = vocab - known_learning_words
        book_stats["unknown_words"] = unknown_words
        book_stats["unknown_count"] = len(unknown_words)
        book_stats["unknown_ratio"] = (
            len(unknown_words) / len(vocab) if vocab else 0
        )

        # BEYOND ä»…ç”¨äºç»Ÿè®¡å±•ç¤º
        book_stats["level_words"]["BEYOND"] = unknown_words
        book_stats["level_counts"]["BEYOND"] = len(unknown_words)
        book_stats["level_ratios"]["BEYOND"] = book_stats["unknown_ratio"]

        # éš¾åº¦è¯„åˆ†ï¼šå­¦ä¹ ç­‰çº§åŠ æƒ + unknown é«˜æƒé‡æƒ©ç½š
        difficulty_score = 0
        for i, level in enumerate(self.learning_levels):
            difficulty_score += book_stats["level_counts"][level] * (i + 1)
        difficulty_score += book_stats["unknown_count"] * 6  # unknown è´¡çŒ®é«˜éš¾åº¦
        book_stats["difficulty_score"] = (
            difficulty_score / len(vocab) if vocab else 0
        )

        # å­¦ä¹ ä»·å€¼ï¼šä»…åŸºäº A1~C1 è¯æ±‡
        learning_value = 0
        for level in self.learning_levels:
            learning_value += (
                book_stats["level_counts"][level] * self.level_weights[level]
            )
        book_stats["learning_value"] = learning_value / len(vocab) if vocab else 0

        # ğŸŒŸ æ–°å¢ï¼šè®¡ç®—è¯¥ä¹¦å¯¹æ¯ä¸ªç­‰çº§çš„"é€‚åˆåº¦"
        # é€‚åˆåº¦ = (ç›®æ ‡ç­‰çº§åŠä»¥ä¸‹è¯æ±‡) / æ€»è¯æ±‡æ•°
        for target_level in self.learning_levels:
            target_idx = self.learning_levels.index(target_level)
            understandable = sum(
                book_stats["level_counts"][self.learning_levels[i]]
                for i in range(target_idx + 1)
            )
            total = len(vocab)  # åŒ…å«æ‰€æœ‰è¯
            book_stats["suitability_for"][target_level] = (
                understandable / total if total > 0 else 0
            )
        
        stats[book_id] = book_stats
    
    return stats
```

### ä¸ºä»€ä¹ˆéœ€è¦è¿™äº›ç»Ÿè®¡ä¿¡æ¯ï¼Ÿ

è¿™äº›é¢„è®¡ç®—çš„ç»Ÿè®¡ä¿¡æ¯æ˜¯ç®—æ³•å†³ç­–çš„åŸºç¡€ï¼š

1. **éš¾åº¦åˆ†æ•°**ï¼šå‘Šè¯‰æˆ‘ä»¬è¿™æœ¬ä¹¦æœ‰å¤šéš¾
   - è®¡ç®—æ–¹å¼ï¼šå°†æ¯ä¸ªå•è¯çš„"éš¾åº¦å€¼"ç›¸åŠ ï¼ˆA1=1, A2=2, B1=3, B2=4, C1=5, è¶…çº²è¯=6ï¼‰
   - é™¤ä»¥æ€»å•è¯æ•°å¾—åˆ°æ ‡å‡†åŒ–éš¾åº¦åˆ†æ•°

2. **å­¦ä¹ ä»·å€¼åˆ†æ•°**ï¼šå‘Šè¯‰æˆ‘ä»¬è¿™æœ¬ä¹¦å¯¹å½“å‰å­¦ä¹ é˜¶æ®µæœ‰å¤šå¤§çš„ä»·å€¼
   - è®¡ç®—æ–¹å¼ï¼šä½çº§åˆ«è¯æ±‡æƒé‡æ›´é«˜ï¼ˆA1=1.5, A2=1.3, B1=1.1, B2=1.0, C1=0.9ï¼‰
   - è¿™æ˜¯å› ä¸ºåˆå­¦è€…ä»åŸºç¡€è¯æ±‡ä¸­è·ç›Šæ›´å¤š

3. **è¶…çº²è¯æ±‡æ¯”ä¾‹**ï¼šå‘Šè¯‰æˆ‘ä»¬è¿™æœ¬ä¹¦æ˜¯å¦å¤ªéš¾
   - æ¯”ä¾‹è¿‡é«˜ï¼ˆ>15%ï¼‰å¯èƒ½è¡¨ç¤ºè¿™æœ¬ä¹¦å¯¹å½“å‰å­¦ä¹ è€…å¤ªéš¾

4. **é€‚åˆåº¦åˆ†æ**ï¼šğŸŒŸæ–°å¢åŠŸèƒ½ï¼Œè¯„ä¼°ä¹¦ç±å¯¹ç‰¹å®šç­‰çº§çš„é€‚åˆç¨‹åº¦
   - è®¡ç®—å…¬å¼ï¼šé€‚åˆåº¦ = (ç›®æ ‡ç­‰çº§åŠä»¥ä¸‹è¯æ±‡æ•°) / æ€»è¯æ±‡æ•°
   - ä¾‹å¦‚ï¼šæŸä¹¦å¯¹B1çš„é€‚åˆåº¦ = (A1è¯æ±‡ + A2è¯æ±‡ + B1è¯æ±‡) / æ€»è¯æ±‡æ•°
   - è¿™ä¸ªæŒ‡æ ‡å¸®åŠ©æˆ‘ä»¬æ›´ç²¾å‡†åœ°åŒ¹é…ä¹¦ç±ä¸å­¦ä¹ è€…æ°´å¹³

## ç¬¬äº”ç‚¹äº”æ­¥ï¼šä¹¦ç±éš¾åº¦è¯„ä¼°åŠŸèƒ½

åœ¨æ ¸å¿ƒç®—æ³•ä¹‹å‰ï¼Œæˆ‘ä»¬è¿˜æä¾›äº†ä¸€ä¸ªç‹¬ç«‹çš„ä¹¦ç±è¯„ä¼°å·¥å…·ï¼š

```python
def evaluate_book_difficulty(self, book_id: str) -> Dict:
    """
    è¯„ä¼°å•æœ¬ä¹¦çš„éš¾åº¦æƒ…å†µï¼ˆç”¨äºè°ƒè¯•å’Œè§£é‡Šï¼‰
    
    Returns:
        {
            "book_id": str,
            "level_breakdown": {"A1": {"count": 100, "ratio": 0.1}, ...},
            "difficulty_analysis": {
                "overall_difficulty_score": 2.3,
                "learning_value_score": 1.8,
                "unknown_ratio": 0.25,
                "suitability_for": {"A1": 0.6, "A2": 0.5, ...}
            },
            "recommendations": ["æœ€é€‚åˆ B1 çº§åˆ«", "è¶…çº²è¯è¾ƒå¤š"]
        }
    """
```

è¿™ä¸ªæ–¹æ³•æä¾›äº†è¯¦ç»†çš„ä¹¦ç±åˆ†æï¼ŒåŒ…æ‹¬ï¼š
- å„ç­‰çº§è¯æ±‡çš„è¯¦ç»†åˆ†å¸ƒ
- ç»¼åˆéš¾åº¦å’Œä»·å€¼è¯„åˆ†
- å¯¹å„ç­‰çº§çš„é€‚åˆåº¦è¯„ä¼°
- åŸºäºæ•°æ®çš„æ¨èå»ºè®®

> ğŸ’¡ **å®ç”¨æŠ€å·§**ï¼šè¿™ä¸ªæ–¹æ³•ç‰¹åˆ«é€‚åˆç”¨äºè°ƒè¯•å’Œå‘ç”¨æˆ·è§£é‡Šä¸ºä»€ä¹ˆæŸæœ¬ä¹¦è¢«æ¨èæˆ–ä¸è¢«æ¨èã€‚

## ç¬¬å…­æ­¥ï¼šæ ¸å¿ƒç®—æ³• - æ¸è¿›å¼é˜…è¯»è·¯å¾„ç”Ÿæˆ

ç°åœ¨ï¼Œæˆ‘ä»¬æ¥åˆ°äº†ç®—æ³•çš„æ ¸å¿ƒéƒ¨åˆ†ï¼š`create_progressive_reading_path()`ã€‚è¿™ä¸ªæ–¹æ³•ä¼šç”Ÿæˆå®Œæ•´çš„é˜…è¯»è·¯å¾„ã€‚

```python
def create_progressive_reading_path(
    self,
    max_books_per_level: Dict[str, int] | None = None,
    target_coverage_per_level: Dict[str, float] | None = None,
    max_unknown_ratio: float = 0.15,
    min_relevant_ratio: float = 0.4,
    min_target_level_words: int = 50,
) -> Dict:
    """
    ä¸»ç®—æ³•ï¼šæ¸è¿›å¼å­¦ä¹ è·¯å¾„ç”Ÿæˆ
    
    å‚æ•°è¯´æ˜:
    - max_books_per_level: æ¯ä¸ªçº§åˆ«æœ€å¤šé€‰æ‹©å‡ æœ¬ä¹¦
    - target_coverage_per_level: æ¯ä¸ªçº§åˆ«å¸Œæœ›è¦†ç›–çš„ç›®æ ‡è¯æ±‡æ¯”ä¾‹
    - max_unknown_ratio: å…è®¸çš„æœ€å¤§è¶…çº²è¯æ±‡æ¯”ä¾‹
    - min_relevant_ratio: æœ€å°ç›¸å…³è¯æ±‡æ¯”ä¾‹ï¼ˆä½¿ç”¨é€‚åˆåº¦æŒ‡æ ‡ï¼‰
    - min_target_level_words: æœ€å°‘ç›®æ ‡ç­‰çº§è¯æ±‡æ•°é‡
    """
    
    # è®¾ç½®é»˜è®¤å‚æ•°ï¼ˆåŸºäºè¯­è¨€å­¦ä¹ ç»éªŒï¼‰
    if max_books_per_level is None:
        max_books_per_level = {"A1": 3, "A2": 3, "B1": 4, "B2": 3, "C1": 2}
    
    if target_coverage_per_level is None:
        target_coverage_per_level = {
            "A1": 0.85,
            "A2": 0.9,
            "B1": 0.9,
            "B2": 0.9,
            "C1": 0.9,
        }
    
    # åˆå§‹åŒ–ç»“æœç»“æ„
    reading_path = {
        "levels": {},
        "total_books": [],
        "cumulative_coverage": {},
    }
    
    # è·Ÿè¸ªå·²è¦†ç›–çš„è¯æ±‡ï¼ˆç”¨äºç¡®ä¿å­¦ä¹ è¿è´¯æ€§ï¼‰
    cumulative_covered = set()
    already_selected_books = set()  # âœ… æ–°å¢ï¼šå…¨å±€è®°å½•å·²é€‰ä¹¦ç±
    
    # æŒ‰CEFRçº§åˆ«é¡ºåºå¤„ç†ï¼ˆä»ç®€å•åˆ°å¤æ‚ï¼‰
    for level in self.learning_levels:
        print(f"\n=== é€‰æ‹© {level} ç­‰çº§ä¹¦ç± ===")
        
        # ä¸ºå½“å‰çº§åˆ«é€‰æ‹©æœ€ä¼˜ä¹¦ç±ç»„åˆ
        level_result = self._select_books_for_level(
            level=level,
            max_books=max_books_per_level.get(level, 2),
            target_coverage=target_coverage_per_level.get(level, 0.8),
            max_unknown_ratio=max_unknown_ratio,
            min_relevant_ratio=min_relevant_ratio,
            min_target_level_words=min_target_level_words,
            already_covered=cumulative_covered,
            already_selected_books=already_selected_books,  # âœ… ä¼ å…¥å·²é€‰ä¹¦ç±
        )
        
        # ä¿å­˜ç»“æœ
        reading_path["levels"][level] = level_result
        selected_books = level_result["selected_books"]
        reading_path["total_books"].extend(selected_books)
        already_selected_books.update(selected_books)  # âœ… æ›´æ–°å…¨å±€å·²é€‰
        
        # æ›´æ–°ç´¯ç§¯è¦†ç›–è¯æ±‡
        for book in selected_books:
            for lvl in self.learning_levels:
                cumulative_covered.update(self.book_stats[book]["level_words"][lvl])
        
        # ç´¯ç§¯è¦†ç›–ç‡ç»Ÿè®¡
        cumulative_stats = {}
        for vocab_level in self.all_levels:
            if vocab_level in self.level_vocab:
                total = len(self.level_vocab[vocab_level])
                covered = len(cumulative_covered & self.level_vocab[vocab_level])
                ratio = covered / total if total > 0 else 0
            else:
                total = covered = "N/A"
                ratio = 0
            cumulative_stats[vocab_level] = {
                "covered": covered,
                "total": total,
                "ratio": ratio,
            }
        
        reading_path["cumulative_coverage"][level] = cumulative_stats
        
        # æ‰“å°è¿›åº¦
        print(f"å®Œæˆ {level} åç´¯ç§¯è¦†ç›–ç‡:")
        for lvl in self.learning_levels:
            ratio = cumulative_stats[lvl]["ratio"]
            print(f"  {lvl}: {ratio:.1%}")
    
    # ç”Ÿæˆæœ€ç»ˆæ‘˜è¦
    reading_path["summary"] = self._generate_path_summary(reading_path)
    
    return reading_path
```

### æ¸è¿›å¼å­¦ä¹ çš„æ ¸å¿ƒæ€æƒ³

è¿™ä¸ªæ–¹æ³•ä½“ç°äº†"**æ¸è¿›å¼å­¦ä¹ **"çš„æ ¸å¿ƒæ€æƒ³ï¼š

1. **æŒ‰é¡ºåºå¤„ç†**ï¼šä»PreA1å¼€å§‹ï¼Œé€æ­¥è¿‡æ¸¡åˆ°B1
2. **ç´¯ç§¯è¦†ç›–**ï¼šè®°å½•å·²å­¦ä¹ çš„è¯æ±‡ï¼Œç¡®ä¿åç»­ä¹¦ç±èƒ½å»ºç«‹åœ¨å·²æœ‰åŸºç¡€ä¸Š
3. **çº§åˆ«éš”ç¦»**ï¼šæ¯ä¸ªçº§åˆ«æœ‰è‡ªå·±çš„ç›®æ ‡å’Œçº¦æŸï¼Œä½†åˆä¸å‰åçº§åˆ«åè°ƒ

> ğŸŒŸ **å…³é”®æ´å¯Ÿ**ï¼šè¯­è¨€å­¦ä¹ ä¸æ˜¯çº¿æ€§çš„ï¼Œä½†è·¯å¾„åº”è¯¥æ˜¯æ¸è¿›çš„ã€‚æˆ‘ä»¬ä¸åº”è¯¥åœ¨è¿˜æ²¡æŒæ¡A1è¯æ±‡æ—¶å°±å¼ºè¿«å­¦ä¹ è€…é˜…è¯»B1ææ–™ã€‚

## ç¬¬ä¸ƒæ­¥ï¼šçº§åˆ«å†…ä¹¦ç±é€‰æ‹©ç®—æ³•

ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ·±å…¥åˆ° `_select_books_for_level()` æ–¹æ³•ï¼Œè¿™æ˜¯å®é™…åšä¹¦ç±é€‰æ‹©çš„åœ°æ–¹ï¼š

```python
def _select_books_for_level(
    self,
    level: str,
    max_books: int,
    target_coverage: float,
    max_unknown_ratio: float,
    min_relevant_ratio: float,
    min_target_level_words: int,
    already_covered: Set[str],
    already_selected_books: Set[str],  # âœ… æ–°å¢å‚æ•°
) -> Dict:
    """
    ä¸ºç‰¹å®šCEFRçº§åˆ«é€‰æ‹©æœ€ä½³ä¹¦ç±ï¼ˆè´ªå¿ƒç®—æ³•ï¼‰
    
    å‚æ•°è¯´æ˜:
    - level: ç›®æ ‡CEFRçº§åˆ«ï¼ˆå¦‚"A1"ï¼‰
    - max_books: è¯¥çº§åˆ«æœ€å¤šé€‰æ‹©å‡ æœ¬ä¹¦
    - target_coverage: å¸Œæœ›è¦†ç›–çš„ç›®æ ‡çº§åˆ«è¯æ±‡æ¯”ä¾‹
    - max_unknown_ratio: å…è®¸çš„æœ€å¤§è¶…çº²è¯æ±‡æ¯”ä¾‹
    - min_relevant_ratio: æœ€å°é€‚åˆåº¦è¦æ±‚
    - min_target_level_words: æœ€å°‘ç›®æ ‡ç­‰çº§è¯æ±‡æ•°é‡
    - already_covered: å·²ç»è¦†ç›–çš„è¯æ±‡ï¼ˆæ¥è‡ªå‰é¢çº§åˆ«çš„å­¦ä¹ ï¼‰
    - already_selected_books: å…¨å±€å·²é€‰ä¹¦ç±ï¼ˆé¿å…é‡å¤é€‰æ‹©ï¼‰
    """
    
    # ç¬¬ä¸€æ­¥ï¼šç­›é€‰å€™é€‰ä¹¦ç±
    candidates = self._filter_books_for_level(
        level=level,
        max_unknown_ratio=max_unknown_ratio,
        min_relevant_ratio=min_relevant_ratio,
        min_target_level_words=min_target_level_words,
    )
    
    # è¿‡æ»¤æ‰å·²è¢«é€‰è¿‡çš„ä¹¦
    candidates = [
        book_id for book_id in candidates if book_id not in already_selected_books
    ]
    
    if not candidates:
        print(f"è­¦å‘Š: {level} æ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„å€™é€‰ä¹¦ç±")
        return {
            "selected_books": [],
            "coverage": 0,
            "new_words_covered": set(),
            "level_stats": {},
        }
    
    # åˆå§‹åŒ–çŠ¶æ€
    selected_books = []
    target_vocab = self.level_vocab[level]
    remaining_words = target_vocab - already_covered  # å°šæœªè¦†ç›–çš„ç›®æ ‡è¯æ±‡
    newly_covered = set()  # æœ¬æ¬¡çº§åˆ«æ–°è¦†ç›–çš„è¯æ±‡
    
    print(
        f"ç›®æ ‡è¯æ±‡: {len(target_vocab)}, å·²è¦†ç›–: {len(already_covered & target_vocab)}, å¾…è¦†ç›–: {len(remaining_words)}"
    )
    
    iteration = 0
    # è´ªå¿ƒç®—æ³•ï¼šè¿­ä»£é€‰æ‹©æœ€ä½³ä¹¦ç±
    while (
        len(selected_books) < max_books
        and len(newly_covered) / len(target_vocab) < target_coverage
        and remaining_words
    ):
        iteration += 1
        best_book = None
        best_score = -float("inf")
        
        # è¯„ä¼°æ¯æœ¬å€™é€‰ä¹¦ï¼Œé€‰æ‹©å¾—åˆ†æœ€é«˜çš„
        for book_id in candidates:
            if book_id in selected_books:  # é˜²æ­¢æœ¬è½®é‡å¤
                continue
            
            # è®¡ç®—è¿™æœ¬ä¹¦çš„ç»¼åˆè¯„åˆ†
            score = self._calculate_book_score_for_level(
                book_id, level, remaining_words, iteration
            )
            
            if score > best_score:
                best_score = score
                best_book = book_id
        
        # æ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„ä¹¦ï¼Œç»ˆæ­¢å¾ªç¯
        if best_book is None:
            break
        
        # é€‰æ‹©æœ€ä½³ä¹¦ç±å¹¶æ›´æ–°çŠ¶æ€
        selected_books.append(best_book)
        new_words = (
            self.book_stats[best_book]["level_words"][level] & remaining_words
        )
        newly_covered.update(new_words)
        remaining_words -= new_words
        
        print(f"  é€‰æ‹©: {best_book}")
        print(f"  æ–°å¢{level}è¯æ±‡: {len(new_words)}")
        print(f"  å½“å‰è¦†ç›–ç‡: {len(newly_covered) / len(target_vocab):.1%}")
    
    return {
        "selected_books": selected_books,
        "coverage": len(newly_covered) / len(target_vocab) if target_vocab else 0,
        "new_words_covered": newly_covered,
        "level_stats": {
            "target_words": len(target_vocab),
            "covered_words": len(newly_covered),
            "books_count": len(selected_books),
        },
    }
```

### è´ªå¿ƒç®—æ³•çš„ä¸‰è¦ç´ 

è¿™ä¸ªæ–¹æ³•å±•ç¤ºäº†è´ªå¿ƒç®—æ³•çš„ä¸‰ä¸ªå…³é”®è¦ç´ ï¼š

1. **å€™é€‰é›†ç­›é€‰**ï¼š`_filter_books_for_level()` ç¡®ä¿æˆ‘ä»¬åªè€ƒè™‘åˆé€‚çš„ä¹¦ç±
2. **è¯„ä»·å‡½æ•°**ï¼š`_calculate_book_score_for_level()` è¯„ä¼°æ¯æœ¬ä¹¦çš„ä»·å€¼
3. **è¿­ä»£é€‰æ‹©**ï¼šæ¯æ¬¡é€‰æ‹©å½“å‰"æœ€ä¼˜"çš„ä¹¦ç±ï¼Œç›´åˆ°æ»¡è¶³æ¡ä»¶

> ğŸ’¡ **è´ªå¿ƒç®—æ³•çš„æœ¬è´¨**ï¼šåœ¨æ¯ä¸€æ­¥éƒ½åšå‡ºå½“å‰çœ‹æ¥æœ€å¥½çš„é€‰æ‹©ï¼Œå¸Œæœ›é€šè¿‡ä¸€ç³»åˆ—å±€éƒ¨æœ€ä¼˜è§£è¾¾åˆ°å…¨å±€æœ€ä¼˜ã€‚

## ç¬¬å…«æ­¥ï¼šå€™é€‰ä¹¦ç±ç­›é€‰

è®©æˆ‘ä»¬çœ‹çœ‹ `_filter_books_for_level()` æ–¹æ³•ï¼Œå®ƒè´Ÿè´£ç¼©å°æœç´¢ç©ºé—´ï¼š

```python
def _filter_books_for_level(
    self,
    level: str,
    max_unknown_ratio: float = 0.15,
    min_relevant_ratio: float = 0.4,
    min_target_level_words: int = 50,
) -> List[str]:
    """
    ä¸ºç‰¹å®šçº§åˆ«ç­›é€‰åˆé€‚çš„å€™é€‰ä¹¦ç±
    
    ç­›é€‰æ ‡å‡†:
    1. è¶…çº²è¯æ±‡æ¯”ä¾‹ä¸èƒ½è¿‡é«˜ï¼ˆé¿å…è¿‡éš¾ï¼‰
    2. ä½¿ç”¨é€‚åˆåº¦æŒ‡æ ‡ä½œä¸ºç›¸å…³æ€§åˆ¤æ–­ï¼ˆæ›´ç›´è§‚ï¼‰
    3. ç›®æ ‡çº§åˆ«è¯æ±‡æ•°é‡è¦è¾¾åˆ°æœ€ä½è¦æ±‚
    """
    candidates = []
    level_idx = self.learning_levels.index(level)
    
    for book_id, stats in self.book_stats.items():
        # ç¡¬çº¦æŸ1ï¼šè¶…çº²è¯æ±‡æ¯”ä¾‹æ§åˆ¶
        if stats["unknown_ratio"] > max_unknown_ratio:
            continue
        
        # ğŸŒŸ ä½¿ç”¨ suitability_for ä½œä¸ºç›¸å…³æ€§æŒ‡æ ‡ï¼ˆæ›´ç›´è§‚ï¼‰
        if stats["suitability_for"][level] < min_relevant_ratio:
            continue
        
        # ç¡¬çº¦æŸ3ï¼šæœ€ä½ç›®æ ‡è¯æ±‡æ•°é‡
        if stats["level_counts"][level] >= min_target_level_words:
            candidates.append(book_id)
    
    # æŒ‰å­¦ä¹ ä»·å€¼æ’åºï¼Œä¼˜å…ˆè€ƒè™‘é«˜ä»·å€¼ä¹¦ç±
    candidates.sort(
        key=lambda x: self.book_stats[x]["learning_value"], reverse=True
    )
    
    print(f"  {level}ç­‰çº§å€™é€‰ä¹¦ç±: {len(candidates)}æœ¬")
    return candidates
```

### ä¸ºä»€ä¹ˆéœ€è¦ç­›é€‰ï¼Ÿ

æƒ³è±¡ä¸€ä¸‹ï¼Œå¦‚æœä½ æœ‰400æœ¬ä¹¦ï¼Œä½†å…¶ä¸­300æœ¬å¯¹å½“å‰çº§åˆ«æ¥è¯´å¤ªéš¾æˆ–å¤ªç®€å•ã€‚ç›´æ¥åœ¨æ‰€æœ‰400æœ¬ä¹¦ä¸­æœç´¢æœ€ä¼˜ç»„åˆä¼šéå¸¸ä½æ•ˆã€‚

é€šè¿‡ç­›é€‰ï¼Œæˆ‘ä»¬å¯ä»¥ï¼š

- å°†æœç´¢ç©ºé—´ä»400æœ¬ç¼©å‡åˆ°50æœ¬å·¦å³
- ç¡®ä¿åªè€ƒè™‘çœŸæ­£åˆé€‚çš„ä¹¦ç±
- æé«˜åç»­è´ªå¿ƒé€‰æ‹©çš„æ•ˆç‡å’Œè´¨é‡

## ç¬¬ä¹æ­¥ï¼šä¹¦ç±è¯„åˆ†ç³»ç»Ÿ

æœ€åï¼Œè®©æˆ‘ä»¬çœ‹çœ‹æ ¸å¿ƒçš„è¯„åˆ†å‡½æ•° `_calculate_book_score_for_level()`ï¼š

```python
def _calculate_book_score_for_level(
    self, book_id: str, level: str, remaining_words: Set[str], iteration: int
) -> float:
    """
    è®¡ç®—ä¹¦ç±åœ¨å½“å‰å­¦ä¹ é˜¶æ®µçš„ç»¼åˆä»·å€¼è¯„åˆ†
    
    è¯„åˆ†ç»´åº¦:
    1. æ–°è¦†ç›–çš„ç›®æ ‡è¯æ±‡æ•°é‡ï¼ˆä¸»è¦ä»·å€¼ï¼‰
    2. åŒ…å«çš„ä½ç­‰çº§è¯æ±‡ï¼ˆå¤ä¹ ä»·å€¼ï¼‰
    3. é€‚é‡çš„é«˜ç­‰çº§è¯æ±‡ï¼ˆé¢„ä¹ ä»·å€¼ï¼‰
    4. è¶…çº²è¯æ±‡æ•°é‡ï¼ˆè´Ÿé¢å› ç´ ï¼‰
    5. å‰©ä½™è¯æ±‡è¦†ç›–æ¯”ä¾‹ï¼ˆåæœŸæƒé‡æ›´é«˜ï¼‰
    """
    stats = self.book_stats[book_id]
    
    # æ ¸å¿ƒä»·å€¼ï¼šæ–°è¦†ç›–çš„ç›®æ ‡ç­‰çº§è¯æ±‡
    new_coverage = len(stats["level_words"][level] & remaining_words)
    if new_coverage == 0:
        return -1  # æ²¡æœ‰æ–°ä»·å€¼ï¼Œç›´æ¥æ·˜æ±°
    
    # åŸºç¡€åˆ†æ•°ï¼šæ–°è¦†ç›–è¯æ±‡æ•°é‡ Ã— æƒé‡
    score = new_coverage * 10
    
    # å¤ä¹ ä»·å€¼ï¼šä½ç­‰çº§è¯æ±‡çš„å·©å›ºä½œç”¨
    level_idx = self.learning_levels.index(level)
    for i in range(level_idx):
        lower_level = self.learning_levels[i]
        score += stats["level_counts"][lower_level] * 0.5
    
    # é¢„ä¹ ä»·å€¼ï¼šé€‚é‡é«˜ç­‰çº§è¯æ±‡çš„é¢„çƒ­ä½œç”¨
    if level_idx < len(self.learning_levels) - 1:
        next_level = self.learning_levels[level_idx + 1]
        # è®¾ç½®ä¸Šé™ï¼Œé¿å…è¿‡åº¦è¶…å‰
        score += min(stats["level_counts"][next_level], 100) * 0.1
    
    # ä»£ä»·æƒ©ç½šï¼šè¶…çº²è¯æ±‡çš„è´Ÿé¢å½±å“
    score -= stats["unknown_count"] * 0.8
    
    # åŠ¨æ€è°ƒæ•´ï¼šåæœŸæ›´é‡è§†è¦†ç›–å‰©ä½™è¯æ±‡
    if iteration > 2:
        coverage_bonus = (
            new_coverage / len(remaining_words) if remaining_words else 0
        )
        score += coverage_bonus * 50  # å‰©ä½™è¯æ±‡è¶Šå°‘ï¼Œè¦†ç›–ä»·å€¼è¶Šé«˜
    
    return score
```

### è¯„åˆ†ç³»ç»Ÿçš„æ™ºæ…§

è¿™ä¸ªè¯„åˆ†ç³»ç»Ÿèåˆäº†è¯­è¨€å­¦ä¹ çš„å¤šä¸ªé‡è¦åŸåˆ™ï¼š

1. **æ–°è¯æ±‡è¦†ç›–**ï¼šè¿™æ˜¯ä¸»è¦ç›®æ ‡ï¼Œæƒé‡æœ€é«˜
2. **å¤ä¹ ä»·å€¼**ï¼šåŒ…å«å·²å­¦è¯æ±‡æœ‰åŠ©äºå·©å›ºè®°å¿†
3. **é¢„ä¹ ä»·å€¼**ï¼šé€‚åº¦æ¥è§¦ä¸‹ä¸€çº§è¯æ±‡ï¼Œä¸ºæœªæ¥å­¦ä¹ åšå‡†å¤‡
4. **éš¾åº¦æ§åˆ¶**ï¼šè¶…çº²è¯æ±‡è¿‡å¤šä¼šé™ä½åˆ†æ•°
5. **åŠ¨æ€è°ƒæ•´**ï¼šåæœŸæ›´æ³¨é‡å¡«è¡¥ç©ºç™½ï¼Œè€Œéé‡å¤è¦†ç›–

> ğŸŒŸ **å…³é”®æ´å¯Ÿ**ï¼šæœ‰æ•ˆçš„è¯­è¨€å­¦ä¹ ä¸æ˜¯ç®€å•åœ°è¦†ç›–è¯æ±‡ï¼Œè€Œæ˜¯è¦åœ¨**æ–°çŸ¥è·å–**ã€**æ—§çŸ¥å·©å›º**å’Œ**éš¾åº¦æ§åˆ¶**ä¹‹é—´æ‰¾åˆ°å¹³è¡¡ã€‚

## ç¬¬åæ­¥ï¼šå®Œæ•´ç¤ºä¾‹æ¼”ç¤º

ç°åœ¨ï¼Œè®©æˆ‘ä»¬è¿è¡Œä¸€ä¸ªå®Œæ•´çš„ç¤ºä¾‹ï¼Œçœ‹çœ‹ç®—æ³•å¦‚ä½•å·¥ä½œï¼š

```python
def demo_layered_usage():
    """æ¼”ç¤ºåˆ†å±‚è¯æ±‡çš„ä½¿ç”¨"""
    import random
    
    random.seed(42)
    
    # æ¨¡æ‹ŸCEFRåˆ†å±‚è¯æ±‡æ•°æ®
    vocab_levels = {}
    level_sizes = {"A1": 800, "A2": 1200, "B1": 1500, "B2": 1800, "C1": 2000}
    
    word_id = 0
    for level, size in level_sizes.items():
        for i in range(size):
            vocab_levels[f"{level.lower()}_word_{i}"] = level
            word_id += 1
    
    # ç”Ÿæˆä¹¦ç±æ•°æ®
    books_vocab = {}
    level_order = ["A1", "A2", "B1", "B2", "C1"]
    
    for i in range(100):  # ç”¨100æœ¬ä¹¦åšæ¼”ç¤º
        book_size = random.randint(2000, 5000)
        book_vocab = set()
        
        # ç¡®å®šä¹¦ç±çš„ä¸»è¦éš¾åº¦ç­‰çº§
        primary_level_idx = random.randint(0, 4)  # 0-4 å¯¹åº” A1-C1
        primary_level = level_order[primary_level_idx]
        
        # åˆ†é…è¯æ±‡ï¼šä¸»è¦ç­‰çº§50%ï¼Œæ›´ä½ç­‰çº§30%ï¼Œæ›´é«˜ç­‰çº§15%ï¼Œè¶…çº²5%
        remaining_size = book_size
        
        # ä¸»è¦ç­‰çº§è¯æ±‡
        primary_words = [w for w, l in vocab_levels.items() if l == primary_level]
        if primary_words:
            count = min(int(book_size * 0.5), len(primary_words), remaining_size)
            book_vocab.update(random.sample(primary_words, count))
            remaining_size -= count
        
        # è¾ƒä½ç­‰çº§è¯æ±‡
        for j in range(primary_level_idx):
            level = level_order[j]
            level_words = [w for w, l in vocab_levels.items() if l == level]
            if level_words and remaining_size > 0:
                count = min(int(book_size * 0.15), len(level_words), remaining_size)
                book_vocab.update(random.sample(level_words, count))
                remaining_size -= count
        
        # è¾ƒé«˜ç­‰çº§è¯æ±‡
        for j in range(primary_level_idx + 1, len(level_order)):
            level = level_order[j]
            level_words = [w for w, l in vocab_levels.items() if l == level]
            if level_words and remaining_size > 0:
                count = min(int(book_size * 0.1), len(level_words), remaining_size)
                book_vocab.update(random.sample(level_words, count))
                remaining_size -= count
        
        # è¶…çº²è¯æ±‡
        if remaining_size > 0:
            out_of_scope = {f"advanced_{i}_{j}" for j in range(remaining_size)}
            book_vocab.update(out_of_scope)
        
        books_vocab[f"book_{primary_level}_{i}"] = book_vocab
    
    # åˆ›å»ºé€‰æ‹©å™¨
    selector = LayeredCEFRBookSelector(books_vocab, vocab_levels)
    
    # è·å–å¤šç§è·¯å¾„æ–¹æ¡ˆ
    paths = selector.get_alternative_paths()
    
    # å±•ç¤ºç»“æœ
    for path_name, path_result in paths:
        selector.print_reading_path(path_result, path_name)
```

### æ¼”ç¤ºç»“æœåˆ†æ

è¿è¡Œæ­¤æ¼”ç¤ºåï¼Œä½ ä¼šçœ‹åˆ°ç±»ä¼¼è¿™æ ·çš„è¾“å‡ºï¼š

```text
==================================================
ğŸ“š æ ‡å‡†è·¯å¾„é˜…è¯»è·¯å¾„
==================================================
æ€»ä¹¦ç±æ•°: 15
å„ç­‰çº§åˆ†å¸ƒ: {'A1': 3, 'A2': 3, 'B1': 4, 'B2': 3, 'C1': 2}

ğŸ“ˆ å­¦ä¹ ç­‰çº§è¦†ç›–ç‡:
  A1: 795/800 (99.4%)
  A2: 1185/1200 (98.8%)
  B1: 1470/1500 (98.0%)
  B2: 1750/1800 (97.2%)
  C1: 1920/2000 (96.0%)
  BEYOND: N/A (éå­¦ä¹ ç›®æ ‡ï¼Œä»…ä¾›å‚è€ƒ)

ğŸ“– æ¨èé˜…è¯»é¡ºåº:

  === A1 ç­‰çº§ ===
   1. book_A1_34
       ç›®æ ‡è¯æ±‡: 254, è¶…çº²è¯: 12, éš¾åº¦: 1.2
   2. book_A1_78
       ç›®æ ‡è¯æ±‡: 248, è¶…çº²è¯: 9, éš¾åº¦: 1.1
   3. book_A1_12
       ç›®æ ‡è¯æ±‡: 280, è¶…çº²è¯: 15, éš¾åº¦: 1.3

  === A2 ç­‰çº§ ===
   4. book_A2_56
       ç›®æ ‡è¯æ±‡: 380, è¶…çº²è¯: 25, éš¾åº¦: 2.1
   5. book_A2_89
       ç›®æ ‡è¯æ±‡: 372, è¶…çº²è¯: 32, éš¾åº¦: 2.0
   6. book_A2_23
       ç›®æ ‡è¯æ±‡: 395, è¶…çº²è¯: 28, éš¾åº¦: 2.2
       
...ï¼ˆå…¶ä½™ä¹¦ç±çœç•¥ï¼‰...
```

è¿™ä¸ªè¾“å‡ºæ¸…æ™°åœ°å±•ç¤ºäº†ï¼š

1. é€‰æ‹©äº†å¤šå°‘æœ¬ä¹¦ï¼Œä»¥åŠå®ƒä»¬å¦‚ä½•åˆ†å¸ƒåœ¨å„ä¸ªçº§åˆ«
2. æœ€ç»ˆè¾¾åˆ°äº†æ€æ ·çš„è¯æ±‡è¦†ç›–ç‡
3. æ¨èçš„é˜…è¯»é¡ºåºï¼ŒåŒ…æ‹¬æ¯æœ¬ä¹¦çš„å…³é”®æŒ‡æ ‡

## ç¬¬åä¸€æ­¥ï¼šå¤šæ–¹æ¡ˆç”Ÿæˆä¸ä¸ªæ€§åŒ–

æœ€åï¼Œè®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•ç”Ÿæˆä¸åŒé£æ ¼çš„é˜…è¯»è·¯å¾„ï¼š

```python
def get_alternative_paths(self) -> List[Tuple[str, Dict]]:
    """
    å¤šæ–¹æ¡ˆç”Ÿæˆç®—æ³•ï¼šå‚æ•°ç©ºé—´æ¢ç´¢

    ç®—æ³•ç±»å‹ï¼šå‚æ•°è°ƒä¼˜ + å¤šç›®æ ‡ä¼˜åŒ–

    ç­–ç•¥ï¼šé€šè¿‡è°ƒæ•´å…³é”®å‚æ•°ç”Ÿæˆä¸åŒç‰¹è‰²çš„è§£å†³æ–¹æ¡ˆ
        - ä¿å®ˆè·¯å¾„ï¼šæ›´æ³¨é‡åŸºç¡€å·©å›ºï¼Œä¸¥æ ¼æ§åˆ¶éš¾åº¦ï¼Œé€‚åˆåˆå­¦è€…
        - æ ‡å‡†è·¯å¾„ï¼šå¹³è¡¡è¦†ç›–ç‡ã€éš¾åº¦å’Œå­¦ä¹ æ•ˆç‡ï¼Œé€‚åˆå¤§å¤šæ•°å­¦ä¹ è€…
        - å¿«é€Ÿè·¯å¾„ï¼šé€‚å½“æ”¾å®½ç­›é€‰æ¡ä»¶ï¼ŒåŠ å¿«å­¦ä¹ è¿›åº¦ï¼Œé€‚åˆæ—¶é—´ç´§å¼ æˆ–åŸºç¡€è¾ƒå¥½çš„å­¦ä¹ è€…

    ç›®çš„ï¼šç»™ç”¨æˆ·æä¾›é€‰æ‹©ç©ºé—´ï¼Œé€‚åº”ä¸åŒå­¦ä¹ éœ€æ±‚ã€ç›®æ ‡å’Œæ—¶é—´å®‰æ’
    """
    paths = []

    # ğŸ›¡ï¸ ä¿å®ˆè·¯å¾„ï¼šå¼ºè°ƒåŸºç¡€ã€ä½å‹åŠ›ã€é«˜è¦†ç›–ç‡
    # é€‚åˆï¼šè¯æ±‡åŸºç¡€è–„å¼±ã€é˜…è¯»é€Ÿåº¦æ…¢ã€å¸Œæœ›ç¨³æ­¥æå‡çš„å­¦ä¹ è€…
    conservative_path = self.create_progressive_reading_path(
        max_books_per_level={"A1": 4, "A2": 4, "B1": 3, "B2": 2, "C1": 1},
        target_coverage_per_level={
            "A1": 0.90,
            "A2": 0.90,
            "B1": 0.85,
            "B2": 0.80,
            "C1": 0.80,
        },
        max_unknown_ratio=0.10,  # ä¸¥æ ¼æ§åˆ¶è¶…çº²è¯ï¼ˆâ‰¤10%ï¼‰
        min_relevant_ratio=0.60,  # è¦æ±‚60%ä»¥ä¸Šæ˜¯å½“å‰åŠä»¥ä¸‹ç­‰çº§è¯æ±‡
        min_target_level_words=50,  # ç¡®ä¿æ¯æœ¬ä¹¦æœ‰è¶³å¤Ÿçš„ç›®æ ‡ç­‰çº§è¯æ±‡
    )
    paths.append(("ä¿å®ˆè·¯å¾„", conservative_path))

    # âš–ï¸ æ ‡å‡†è·¯å¾„ï¼šå¹³è¡¡å„é¡¹æŒ‡æ ‡
    # é€‚åˆï¼šå¤§å¤šæ•°ä¸­çº§å­¦ä¹ è€…ï¼Œå¸Œæœ›ç³»ç»Ÿå­¦ä¹ ã€ç¨³æ­¥è¿›é˜¶
    standard_path = self.create_progressive_reading_path(
        max_books_per_level={"A1": 3, "A2": 3, "B1": 4, "B2": 3, "C1": 2},
        target_coverage_per_level={
            "A1": 0.85,
            "A2": 0.90,
            "B1": 0.90,
            "B2": 0.90,
            "C1": 0.90,
        },
        max_unknown_ratio=0.15,  # å…è®¸é€‚åº¦æŒ‘æˆ˜
        min_relevant_ratio=0.40,  # ä¸­ç­‰åŸºç¡€è¯æ±‡è¦æ±‚
        min_target_level_words=30,
    )
    paths.append(("æ ‡å‡†è·¯å¾„", standard_path))

    # ğŸš€ å¿«é€Ÿè·¯å¾„ï¼šè¿½æ±‚æ•ˆç‡ï¼Œå®¹å¿æ›´é«˜éš¾åº¦
    # é€‚åˆï¼šåŸºç¡€è¾ƒå¥½ã€æ—¶é—´æœ‰é™ã€å¸Œæœ›é€šè¿‡å¤§é‡é˜…è¯»å¿«é€Ÿæå‡çš„å­¦ä¹ è€…
    fast_path = self.create_progressive_reading_path(
        max_books_per_level={"A1": 2, "A2": 3, "B1": 4, "B2": 3, "C1": 3},
        target_coverage_per_level={
            "A1": 0.75,
            "A2": 0.80,
            "B1": 0.85,
            "B2": 0.85,
            "C1": 0.85,
        },
        max_unknown_ratio=0.25,  # å…è®¸æœ€å¤š25%è¶…çº²è¯
        min_relevant_ratio=0.30,  # æ¥å—è¾ƒä½çš„åŸºç¡€è¯æ±‡æ¯”ä¾‹
        min_target_level_words=10,  # åªè¦å‡ºç°å°‘é‡ç›®æ ‡è¯å³å¯
    )
    paths.append(("å¿«é€Ÿè·¯å¾„", fast_path))

    return paths
```

### ä¸ºä»€ä¹ˆéœ€è¦å¤šæ–¹æ¡ˆï¼Ÿ

ä¸åŒçš„å­¦ä¹ è€…æœ‰ä¸åŒçš„éœ€æ±‚ï¼š

- **ä¿å®ˆå‹å­¦ä¹ è€…**ï¼šåŸºç¡€è¾ƒå¼±ï¼Œéœ€è¦æ›´å¤šç»ƒä¹ å’Œå·©å›º
- **æ ‡å‡†å‹å­¦ä¹ è€…**ï¼šè¿½æ±‚å¹³è¡¡ï¼Œå¸Œæœ›ç¨³æ­¥æå‡
- **å¿«é€Ÿå‹å­¦ä¹ è€…**ï¼šåŸºç¡€è¾ƒå¥½ï¼Œå¸Œæœ›å°½å¿«è¾¾åˆ°ç›®æ ‡

é€šè¿‡è°ƒæ•´å…³é”®å‚æ•°ï¼Œæˆ‘ä»¬å¯ä»¥ä¸ºä¸åŒå­¦ä¹ è€…å®šåˆ¶æœ€é€‚åˆçš„è·¯å¾„ã€‚

## ç®—æ³•æ€»ç»“ä¸æ€è€ƒ

æˆ‘ä»¬çš„åˆ†å±‚è´ªå¿ƒç®—æ³•æˆåŠŸè§£å†³äº†æ¸è¿›å¼é˜…è¯»è·¯å¾„è§„åˆ’é—®é¢˜ï¼Œå…³é”®åœ¨äºï¼š

1. **é—®é¢˜åˆ†è§£**ï¼šå°†å¤æ‚çš„å…¨å±€ä¼˜åŒ–é—®é¢˜åˆ†è§£ä¸ºæŒ‰çº§åˆ«çš„å­é—®é¢˜ï¼ˆA1â†’A2â†’B1â†’B2â†’C1ï¼‰
2. **é¢„å¤„ç†**ï¼šé€šè¿‡é¢„è®¡ç®—ç»Ÿè®¡ä¿¡æ¯æé«˜æ•ˆç‡
3. **å¤šç»´è¯„ä»·**ï¼šç»¼åˆè€ƒè™‘è¯æ±‡è¦†ç›–ã€éš¾åº¦æ§åˆ¶å’Œå­¦ä¹ è¿è´¯æ€§
4. **æ¸è¿›å¼ç­–ç•¥**ï¼šç¡®ä¿å­¦ä¹ è·¯å¾„å¹³æ»‘ä¸Šå‡
5. **ğŸŒŸé€‚åˆåº¦åˆ†æ**ï¼šå¼•å…¥ä¹¦ç±å¯¹ç‰¹å®šç­‰çº§çš„é€‚åˆåº¦è¯„ä¼°ï¼Œæé«˜åŒ¹é…ç²¾åº¦
6. **ğŸŒŸå…¨å±€å»é‡**ï¼šé¿å…åœ¨ä¸åŒç­‰çº§é‡å¤é€‰æ‹©åŒä¸€æœ¬ä¹¦
7. **ğŸŒŸè¶…çº²è¯å¤„ç†**ï¼šå°†æœªåœ¨å­¦ä¹ è¯è¡¨ä¸­çš„è¯æ±‡æ ‡è®°ä¸ºBEYONDï¼Œæ›´è´´è¿‘å®é™…å­¦ä¹ åœºæ™¯

### æ ¸å¿ƒåˆ›æ–°ç‚¹

1. **é€‚åˆåº¦æŒ‡æ ‡**ï¼š`suitability_for[level] = (ç›®æ ‡ç­‰çº§åŠä»¥ä¸‹è¯æ±‡) / æ€»è¯æ±‡æ•°`
   - è¿™æ¯”ä¼ ç»Ÿçš„"ç›¸å…³è¯æ±‡æ¯”ä¾‹"æ›´ç›´è§‚å’Œå‡†ç¡®
   - ç›´æ¥å›ç­”"è¿™æœ¬ä¹¦æœ‰å¤šé€‚åˆA1å­¦ä¹ è€…ï¼Ÿ"çš„é—®é¢˜

2. **BEYONDè¯æ±‡å¤„ç†**ï¼š
   - ç°å®ä¸­ï¼Œä¹¦ç±æ€»åŒ…å«ä¸€äº›è¶…å‡ºæ•™å­¦å¤§çº²çš„è¯æ±‡
   - ç®—æ³•å°†å…¶å•ç‹¬æ ‡è®°ï¼Œè€Œéç®€å•å¿½ç•¥
   - åœ¨éš¾åº¦è¯„ä¼°æ—¶ç»™äºˆé«˜æƒé‡æƒ©ç½šï¼ˆÃ—6ï¼‰

3. **å¤šæ–¹æ¡ˆç”Ÿæˆ**ï¼š
   - ä¿å®ˆè·¯å¾„ï¼šé€‚åˆåŸºç¡€è–„å¼±å­¦ä¹ è€…
   - æ ‡å‡†è·¯å¾„ï¼šå¹³è¡¡å„é¡¹æŒ‡æ ‡
   - å¿«é€Ÿè·¯å¾„ï¼šé€‚åˆæ—¶é—´ç´§å¼ æˆ–åŸºç¡€è¾ƒå¥½çš„å­¦ä¹ è€…

### æ€è€ƒä¸æ‰©å±•

è¿™ä¸ªç®—æ³•è¿˜æœ‰å¾ˆå¤§çš„æ”¹è¿›ç©ºé—´ï¼š

1. **ä¸ªæ€§åŒ–è°ƒæ•´**ï¼šå¯ä»¥åŸºäºå­¦ä¹ è€…çš„å†å²æ•°æ®è°ƒæ•´æƒé‡
2. **å†…å®¹å¤šæ ·æ€§**ï¼šé¿å…é€‰æ‹©ä¸»é¢˜è¿‡äºç›¸ä¼¼çš„ä¹¦ç±  
3. **é˜…è¯»éš¾åº¦**ï¼šè€ƒè™‘å¥å­å¤æ‚åº¦ã€ä¸»é¢˜ç†Ÿæ‚‰åº¦ç­‰å› ç´ 
4. **åŠ¨æ€è°ƒæ•´**ï¼šæ ¹æ®å­¦ä¹ è¿›åº¦å®æ—¶è°ƒæ•´åç»­æ¨è
5. **äº¤äº’å¼ä¼˜åŒ–**ï¼šå…è®¸ç”¨æˆ·åé¦ˆæ¥ä¼˜åŒ–æ¨èç»“æœ

### ä½ çš„ä»»åŠ¡

ç°åœ¨ï¼Œè½®åˆ°ä½ äº†ï¼å°è¯•ä»¥ä¸‹ç»ƒä¹ ï¼š

1. **å‚æ•°è°ƒä¼˜å®éªŒ**ï¼š
   - ä¿®æ”¹ `level_weights` å‚æ•°ï¼Œè§‚å¯Ÿå¯¹ä¹¦ç±é€‰æ‹©çš„å½±å“
   - è°ƒæ•´ `min_relevant_ratio` å’Œ `min_target_level_words`ï¼Œçœ‹å¦‚ä½•å½±å“å€™é€‰ä¹¦ç±æ•°é‡

2. **åŠŸèƒ½æ‰©å±•**ï¼š
   - å®ç°ä¸€ä¸ªæ–¹æ³•ï¼Œåˆ†æä¸¤æœ¬ä¹¦ä¹‹é—´çš„"éš¾åº¦è·³è·ƒ"ï¼Œç¡®ä¿è·¯å¾„å¹³æ»‘
   - æ·»åŠ ä¹¦ç±ä¸»é¢˜å¤šæ ·æ€§è¯„ä¼°ï¼Œé¿å…é€‰æ‹©å†…å®¹è¿‡äºç›¸ä¼¼çš„ä¹¦ç±

3. **è¯„ä¼°ä½“ç³»ä¼˜åŒ–**ï¼š
   - å°è¯•æ”¹è¿› `evaluate_book_difficulty` æ–¹æ³•ï¼Œæ·»åŠ æ›´å¤šæœ‰ç”¨çš„åˆ†æç»´åº¦
   - å®ç°ä¹¦ç±æ¨èçš„"è§£é‡Šæ€§"åŠŸèƒ½ï¼Œå‘Šè¯‰ç”¨æˆ·ä¸ºä»€ä¹ˆé€‰æ‹©è¿™æœ¬ä¹¦

4. **ç”¨æˆ·ç•Œé¢è®¾è®¡**ï¼š
   - è®¾è®¡ä¸€ä¸ªWebç•Œé¢ï¼Œè®©éæŠ€æœ¯ç”¨æˆ·ä¹Ÿèƒ½ä½¿ç”¨è¿™ä¸ªç®—æ³•
   - æ·»åŠ å¯è§†åŒ–åŠŸèƒ½ï¼Œå±•ç¤ºå­¦ä¹ è·¯å¾„å’Œè¯æ±‡è¦†ç›–ç‡è¿›å±•

5. **é«˜çº§æŒ‘æˆ˜**ï¼š
   - å®ç°ä¸ªæ€§åŒ–æƒé‡å­¦ä¹ ï¼Œæ ¹æ®ç”¨æˆ·åé¦ˆè°ƒæ•´ç®—æ³•å‚æ•°
   - è€ƒè™‘æ·»åŠ B2+ã€C2ç­‰æ›´é«˜çº§åˆ«çš„æ”¯æŒ

## ç»“è¯­

é€šè¿‡è¿™ä¸ªæ•™ç¨‹ï¼Œä½ å·²ç»æŒæ¡äº†åˆ†å±‚è´ªå¿ƒç®—æ³•çš„æ ¸å¿ƒæ€æƒ³å’Œå®ç°ç»†èŠ‚ã€‚ä»A1åŸºç¡€è¯æ±‡åˆ°C1é«˜çº§è¡¨è¾¾ï¼Œè¿™ä¸ªç®—æ³•ä¸ºè‹±è¯­å­¦ä¹ è€…æä¾›äº†ä¸€æ¡ç§‘å­¦ã€ç³»ç»Ÿçš„é˜…è¯»è·¯å¾„ã€‚

### ç®—æ³•çš„æ™®é€‚æ€§

è¿™ç§åˆ†å±‚è´ªå¿ƒæ€æƒ³ä¸ä»…é€‚ç”¨äºè‹±è¯­é˜…è¯»è·¯å¾„è§„åˆ’ï¼Œè¿˜å¯ä»¥å¹¿æ³›åº”ç”¨äºï¼š

- **åœ¨çº¿æ•™è‚²**ï¼šè¯¾ç¨‹å†…å®¹çš„æ¸è¿›å¼ç¼–æ’
- **æŠ€èƒ½åŸ¹è®­**ï¼šä»åˆçº§åˆ°é«˜çº§çš„èƒ½åŠ›å»ºè®¾è·¯å¾„
- **æ¸¸æˆè®¾è®¡**ï¼šå…³å¡éš¾åº¦çš„å¹³æ»‘è¿‡æ¸¡
- **çŸ¥è¯†ç®¡ç†**ï¼šæ¦‚å¿µå­¦ä¹ çš„ä¾èµ–å…³ç³»å¤„ç†
- **èŒä¸šå‘å±•**ï¼šæŠ€èƒ½æ ‘å’Œå­¦ä¹ è·¯çº¿å›¾è§„åˆ’

### æ ¸å¿ƒå¯å‘

1. **æ¸è¿›å¼åŸåˆ™**ï¼šä»»ä½•å¤æ‚æŠ€èƒ½çš„ä¹ å¾—éƒ½éœ€è¦å¾ªåºæ¸è¿›
2. **å¤šç»´è¯„ä¼°**ï¼šå•ä¸€æŒ‡æ ‡å¾€å¾€ä¸è¶³ä»¥åšå‡ºæœ€ä¼˜å†³ç­–
3. **ä¸ªæ€§åŒ–é€‚é…**ï¼šåŒä¸€ä¸ªç®—æ³•æ¡†æ¶å¯ä»¥é€šè¿‡å‚æ•°è°ƒæ•´é€‚åº”ä¸åŒéœ€æ±‚
4. **æ•°æ®é©±åŠ¨**ï¼šåŸºäºå®¢è§‚æ•°æ®è€Œéä¸»è§‚ç»éªŒåšå†³ç­–

è®°ä½ï¼Œå¥½çš„ç®—æ³•ä¸ä»…ä»…æ˜¯æ•°å­¦ä¸Šçš„æœ€ä¼˜ï¼Œæ›´è¦ç¬¦åˆäººç±»çš„è®¤çŸ¥è§„å¾‹å’Œå­¦ä¹ ç‰¹ç‚¹ã€‚æˆ‘ä»¬çš„é€‚åˆåº¦åˆ†æã€è¶…çº²è¯å¤„ç†ç­‰åˆ›æ–°ï¼Œæ­£æ˜¯å°†ç®—æ³•ç†è®ºä¸æ•™è‚²å®è·µç›¸ç»“åˆçš„ä½“ç°ã€‚

å¸Œæœ›è¿™ä¸ªæ•™ç¨‹ä¸ä»…å¸®ä½ ç†è§£äº†ç®—æ³•æœ¬èº«ï¼Œæ›´é‡è¦çš„æ˜¯å¯å‘ä½ æ€è€ƒå¦‚ä½•ç”¨æŠ€æœ¯æ‰‹æ®µè§£å†³ç°å®ä¸­çš„å­¦ä¹ é—®é¢˜ã€‚

> "æ•™è‚²ä¸æ˜¯å¡«æ»¡ä¸€æ¡¶æ°´ï¼Œè€Œæ˜¯ç‚¹ç‡ƒä¸€æŠŠç«ã€‚" â€” å¨å»‰Â·å·´ç‰¹å‹’Â·å¶èŠ  
> "ç®—æ³•ä¸æ˜¯å†°å†·çš„æ•°å­¦å…¬å¼ï¼Œè€Œæ˜¯ç†è§£äººæ€§çš„æ™ºæ…§ç»“æ™¶ã€‚" â€” æœ¬æ•™ç¨‹ä½œè€…

Happy coding and happy learning! ğŸ“šâœ¨ğŸš€

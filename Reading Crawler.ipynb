{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce15c68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from pathlib import Path\n",
    "\n",
    "import httpx\n",
    "from lxml import etree\n",
    "\n",
    "\n",
    "async def get_book_articles(book_id: str):\n",
    "    \"\"\"\n",
    "    异步获取扇贝阅读文章的API数据\n",
    "\n",
    "    Returns:\n",
    "        dict: 包含API响应数据的字典\n",
    "    \"\"\"\n",
    "    url = f\"https://apiv3.shanbay.com/reading/admin/books/{book_id}/articles\"\n",
    "    params = {\"list_all\": \"true\"}\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Cookie\": Path(\"cookies.txt\").read_text().strip(),\n",
    "    }\n",
    "\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        response = await client.get(\n",
    "            url=url,\n",
    "            params=params,\n",
    "            headers=headers,\n",
    "            timeout=10.0,  # 设置10秒超时\n",
    "        )\n",
    "        response.raise_for_status()  # 如果响应状态码不是200，抛出异常\n",
    "        response_data = response.json()\n",
    "        return [i[\"id\"] for i in response_data[\"objects\"]]\n",
    "\n",
    "\n",
    "async def get_article_paragraphs(article_id: str):\n",
    "    \"\"\"\n",
    "    异步获取文章段落的API数据(curl -X GET \"https://apiv3.shanbay.com/reading/admin/articles/{article_id}/paragraphs\" -H \"accept: application/json\")\n",
    "\n",
    "    Returns:\n",
    "        dict: 包含API响应数据的字典\n",
    "    \"\"\"\n",
    "    url = f\"https://apiv3.shanbay.com/reading/admin/articles/{article_id}/paragraphs\"\n",
    "    params = {\"list_all\": \"true\"}\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Cookie\": Path(\"cookies.txt\").read_text().strip(),\n",
    "    }\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        response = await client.get(\n",
    "            url=url,\n",
    "            params=params,\n",
    "            headers=headers,\n",
    "            timeout=10.0,  # 设置10秒超时\n",
    "        )\n",
    "        response.raise_for_status()  # 如果响应状态码不是200，抛出异常\n",
    "        response_data = response.json()\n",
    "        return [i[\"content\"] for i in response_data[\"objects\"]]\n",
    "\n",
    "\n",
    "def parse_paragraphs_to_sentences(paragraphs_raw: str):\n",
    "    \"\"\"\n",
    "    解析段落原字符串\n",
    "\n",
    "    Args:\n",
    "        paragraphs (list): 段落列表，每个元素为一个段落字符串\n",
    "\n",
    "    Returns:\n",
    "        list: 合并后的段落列表\n",
    "    \"\"\"\n",
    "    doc = etree.fromstring(paragraphs_raw)\n",
    "    sentences = doc.xpath(\"//sent\")\n",
    "    return [i.text for i in sentences]\n",
    "\n",
    "\n",
    "async def get_all_sentences_from_book(book_id: str):\n",
    "    \"\"\"\n",
    "    异步获取书籍所有段落的API数据\n",
    "\n",
    "    Returns:\n",
    "        dict: 包含API响应数据的字典\n",
    "    \"\"\"\n",
    "    article_ids = await get_book_articles(book_id=book_id)\n",
    "    # for article_id in article_ids:\n",
    "    #     paragraphs = await get_article_paragraphs(article_id=article_id)\n",
    "    #     for paragraph in paragraphs:\n",
    "    #         sentences = parse_paragraphs_to_sentences(paragraphs_raw=paragraph)\n",
    "    #         for sentence in sentences:\n",
    "    #             print(sentence)\n",
    "    # paragraphs = await asyncio.gather(\n",
    "    #     *[get_article_paragraphs(article_id) for article_id in article_ids]\n",
    "    # )\n",
    "    tasks = []\n",
    "    for article_id in article_ids:\n",
    "        tasks.append(asyncio.create_task(get_article_paragraphs(article_id=article_id)))\n",
    "        await asyncio.sleep(0.3)\n",
    "    paragraphs = await asyncio.gather(*tasks)\n",
    "    paragraphs_unzipped = []\n",
    "    for paragraph in paragraphs:\n",
    "        paragraphs_unzipped.extend(paragraph)\n",
    "    sentences = []\n",
    "    for paragraph in paragraphs_unzipped:\n",
    "        sentences.extend(parse_paragraphs_to_sentences(paragraphs_raw=paragraph))\n",
    "    return sentences\n",
    "\n",
    "\n",
    "sentences = await get_all_sentences_from_book(\"gjozx\")\n",
    "for i in sentences:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fd924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "books = pd.read_csv(\"books.csv\")\n",
    "for book in books.itertuples():\n",
    "    book_path = Path(f\"book_sentence/{book.ID}-{book.中文}.txt\")\n",
    "    if book_path.exists():\n",
    "        continue\n",
    "    print(book.ID, book.中文)\n",
    "    sentences = await get_all_sentences_from_book(book.ID)\n",
    "    sentences = \"\\n\".join(sentences)\n",
    "    book_path.write_text(data=sentences)\n",
    "    time.sleep(0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

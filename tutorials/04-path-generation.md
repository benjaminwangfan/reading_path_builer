# 04. è·¯å¾„ç”Ÿæˆç®—æ³•ï¼šå¤šå±‚è´ªå¿ƒç­–ç•¥çš„æ™ºæ…§

> *"è´ªå¿ƒç®—æ³•çš„è‰ºæœ¯åœ¨äºï¼šåœ¨æ¯ä¸ªå…³é”®æ—¶åˆ»ï¼Œåšå‡ºå½“å‰çœ‹æ¥æœ€æ˜æ™ºçš„é€‰æ‹©ï¼Œå¹¶ç›¸ä¿¡è¿™äº›å±€éƒ¨æœ€ä¼˜èƒ½é€šå‘å…¨å±€æœ€ä¼˜ã€‚"*

åœ¨å‰é¢çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬å»ºç«‹äº†é…ç½®ç³»ç»Ÿå’Œåˆ†æå¼•æ“ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬å°†æ¢ç´¢ç³»ç»Ÿçš„"æ™ºæ…§æ ¸å¿ƒ"â€”â€”**è·¯å¾„ç”Ÿæˆç®—æ³•**ã€‚è¿™æ˜¯ä¸€ä¸ªç²¾å¿ƒè®¾è®¡çš„å¤šå±‚è´ªå¿ƒç®—æ³•ï¼Œå®ƒèƒ½åœ¨æˆåƒä¸Šä¸‡æœ¬ä¹¦ä¸­æ‰¾åˆ°æœ€ä¼˜çš„å­¦ä¹ è·¯å¾„ã€‚

## ğŸ§  ç®—æ³•è®¾è®¡å“²å­¦

### æ ¸å¿ƒæŒ‘æˆ˜ï¼šå¤šç›®æ ‡ä¼˜åŒ–

è·¯å¾„ç”Ÿæˆé¢ä¸´çš„æ˜¯ä¸€ä¸ªå¤æ‚çš„å¤šç›®æ ‡ä¼˜åŒ–é—®é¢˜ï¼š

```text
ç»™å®šï¼š
- Næœ¬ä¹¦ï¼Œæ¯æœ¬ä¹¦æœ‰è¯æ±‡åˆ†å¸ƒ V_i
- Mä¸ªéš¾åº¦çº§åˆ« L_1, L_2, ..., L_M  
- æ¯ä¸ªçº§åˆ«çš„ç›®æ ‡è¦†ç›–ç‡ C_1, C_2, ..., C_M
- å„ç§çº¦æŸæ¡ä»¶ï¼ˆä¹¦ç±æ•°é‡ã€éš¾åº¦é™åˆ¶ç­‰ï¼‰

æ±‚è§£ï¼š
- é€‰æ‹©ä¹¦ç±å­é›† S âŠ† {1,2,...,N}
- æœ€å¤§åŒ–è¯æ±‡è¦†ç›–ç‡
- æœ€å°åŒ–éš¾åº¦è·³è·ƒ
- ç¡®ä¿å­¦ä¹ è·¯å¾„çš„å¹³æ»‘æ€§
```

è¿™æ˜¯ä¸€ä¸ª**NP-hard**é—®é¢˜ã€‚å¦‚æœç”¨æš´åŠ›æœç´¢ï¼Œæ—¶é—´å¤æ‚åº¦æ˜¯O(2^N)ï¼Œå¯¹äºç°å®åº”ç”¨å®Œå…¨ä¸å¯è¡Œã€‚

### åˆ†è€Œæ²»ä¹‹ + è´ªå¿ƒç­–ç•¥

æˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆé‡‡ç”¨**åˆ†å±‚è´ªå¿ƒ**ç­–ç•¥ï¼š

```text
æ•´ä½“é—®é¢˜ï¼šä¸ºæ‰€æœ‰çº§åˆ«é€‰æ‹©æœ€ä¼˜ä¹¦ç±
    â†“
åˆ†è§£ï¼šä¸ºæ¯ä¸ªçº§åˆ«å•ç‹¬é€‰æ‹©æœ€ä¼˜ä¹¦ç±
    â†“
è´ªå¿ƒï¼šåœ¨æ¯ä¸ªçº§åˆ«å†…ï¼Œè¿­ä»£é€‰æ‹©å½“å‰æœ€ä¼˜ä¹¦ç±
```

**æ ¸å¿ƒæ´å¯Ÿ**ï¼šè™½ç„¶å…¨å±€æœ€ä¼˜éš¾ä»¥ç›´æ¥æ±‚è§£ï¼Œä½†é€šè¿‡åˆç†çš„é—®é¢˜åˆ†è§£å’Œå¯å‘å¼è¯„åˆ†ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°æ¥è¿‘æœ€ä¼˜çš„å®ç”¨è§£ã€‚

## ğŸ—ï¸ GenericPathGeneratorï¼šç®—æ³•æ ¸å¿ƒ

### ä¸»ç®—æ³•æµç¨‹

```python
def create_progressive_reading_path(self, books_analysis, target_vocabulary, path_parameters):
    """
    ä¸»ç®—æ³•ï¼šæ¸è¿›å¼é˜…è¯»è·¯å¾„ç”Ÿæˆ
    
    æ ¸å¿ƒæ€è·¯ï¼š
    1. æŒ‰çº§åˆ«é¡ºåºå¤„ç†ï¼ˆA1 â†’ A2 â†’ B1 â†’ B2 â†’ C1ï¼‰
    2. ä¸ºæ¯ä¸ªçº§åˆ«è´ªå¿ƒé€‰æ‹©æœ€ä¼˜ä¹¦ç±ç»„åˆ
    3. ç»´æŠ¤å…¨å±€çŠ¶æ€ï¼ˆå·²è¦†ç›–è¯æ±‡ã€å·²é€‰ä¹¦ç±ï¼‰
    4. ç¡®ä¿å­¦ä¹ è·¯å¾„çš„è¿è´¯æ€§å’Œé€’è¿›æ€§
    """
    
    reading_path_levels = {}
    total_books = []
    cumulative_coverage = {}
    
    # å…¨å±€çŠ¶æ€è·Ÿè¸ª
    cumulative_covered = set()      # å·²è¦†ç›–çš„è¯æ±‡
    already_selected_books = set()  # å·²é€‰æ‹©çš„ä¹¦ç±
    
    # ğŸŒŸ æ ¸å¿ƒå¾ªç¯ï¼šæŒ‰çº§åˆ«é¡ºåºå¤„ç†
    for level in self.config.levels:
        print(f"\n=== é€‰æ‹© {level} ç­‰çº§ä¹¦ç± ===")
        
        # ä¸ºå½“å‰çº§åˆ«é€‰æ‹©æœ€ä¼˜ä¹¦ç±
        level_result = self.select_books_for_level(
            target_level=level,
            candidates=list(books_analysis.keys()),
            books_analysis=books_analysis,
            target_vocabulary=target_vocabulary,
            selection_criteria=self._create_selection_criteria(level, path_parameters),
            already_covered=cumulative_covered,
            already_selected_books=already_selected_books,
            max_books=path_parameters.max_books_per_level.get(level, 2),
            target_coverage=path_parameters.target_coverage_per_level.get(level, 0.8)
        )
        
        # æ›´æ–°å…¨å±€çŠ¶æ€
        selected_books = level_result.selected_books
        total_books.extend(selected_books)
        already_selected_books.update(selected_books)
        
        # æ›´æ–°ç´¯ç§¯è¦†ç›–è¯æ±‡
        for book_id in selected_books:
            book_analysis = books_analysis[book_id]
            for vocab_level in self.config.levels:
                if vocab_level in book_analysis.level_distributions:
                    cumulative_covered.update(
                        book_analysis.level_distributions[vocab_level].words
                    )
        
        # ä¿å­˜ç»“æœ
        reading_path_levels[level] = level_result
        cumulative_coverage[level] = self._calculate_cumulative_coverage(
            cumulative_covered, target_vocabulary
        )
    
    return ReadingPathResult(...)
```

### å…³é”®è®¾è®¡å†³ç­–è§£æ

#### 1. ä¸ºä»€ä¹ˆæŒ‰çº§åˆ«é¡ºåºå¤„ç†ï¼Ÿ

**è¯­è¨€å­¦ä¹ çš„è®¤çŸ¥è§„å¾‹**ï¼š

- å­¦ä¹ è€…éœ€è¦åœ¨åŸºç¡€ç‰¢å›ºåå†è¿›å…¥ä¸‹ä¸€é˜¶æ®µ
- è¯æ±‡ä¹ å¾—å…·æœ‰å±‚æ¬¡æ€§å’Œä¾èµ–æ€§
- è¿‡æ—©æ¥è§¦é«˜éš¾åº¦ææ–™ä¼šå½±å“å­¦ä¹ æ•ˆæœ

**ç®—æ³•ä¼˜åŠ¿**ï¼š

- ä¿è¯è·¯å¾„çš„**è¿è´¯æ€§**ï¼šæ¯ä¸ªçº§åˆ«éƒ½å»ºç«‹åœ¨å‰é¢çº§åˆ«çš„åŸºç¡€ä¸Š
- ç®€åŒ–**çŠ¶æ€ç®¡ç†**ï¼šåªéœ€ç»´æŠ¤å·²è¦†ç›–è¯æ±‡çš„ç´¯ç§¯çŠ¶æ€
- é™ä½**è®¡ç®—å¤æ‚åº¦**ï¼šä»O(2^N)é™ä½åˆ°O(MÃ—NÃ—log N)

#### 2. ä¸ºä»€ä¹ˆä½¿ç”¨è´ªå¿ƒç­–ç•¥ï¼Ÿ

**å…¨å±€æœ€ä¼˜ vs å®ç”¨å¯è¡Œ**ï¼š

```python
# âŒ ç†è®ºæœ€ä¼˜ä½†ä¸å¯è¡Œ
def find_optimal_path_exhaustive(books, levels):
    best_score = -1
    best_path = None
    
    # éå†æ‰€æœ‰å¯èƒ½çš„ä¹¦ç±ç»„åˆ - O(2^N)
    for book_combination in all_combinations(books):
        score = evaluate_path_quality(book_combination)
        if score > best_score:
            best_score = score
            best_path = book_combination
    
    return best_path  # éœ€è¦å‡ åå¹´æ‰èƒ½ç®—å®Œï¼

# âœ… è´ªå¿ƒè¿‘ä¼¼ä½†é«˜æ•ˆ
def find_good_path_greedy(books, levels):
    path = []
    remaining_words = target_vocabulary.copy()
    
    for level in levels:
        # åœ¨å½“å‰çº§åˆ«é€‰æ‹©æœ€ä¼˜ä¹¦ç± - O(NÃ—log N)
        level_books = select_best_books_for_level(
            books, level, remaining_words
        )
        path.extend(level_books)
        update_remaining_words(remaining_words, level_books)
    
    return path  # å‡ ç§’é’Ÿå°±èƒ½ç®—å®Œï¼
```

## ğŸ¯ çº§åˆ«å†…ä¹¦ç±é€‰æ‹©ï¼šè´ªå¿ƒç®—æ³•çš„ç²¾é«“

### æ ¸å¿ƒç®—æ³•å®ç°

```python
def select_books_for_level(self, target_level, candidates, books_analysis, 
                          target_vocabulary, selection_criteria, 
                          already_covered, already_selected_books, 
                          max_books, target_coverage):
    """
    å•çº§åˆ«ä¹¦ç±é€‰æ‹©ï¼šè´ªå¿ƒç®—æ³•æ ¸å¿ƒ
    
    ç®—æ³•æ­¥éª¤ï¼š
    1. ç­›é€‰åˆæ ¼å€™é€‰ä¹¦ç±
    2. åˆå§‹åŒ–çŠ¶æ€ï¼ˆç›®æ ‡è¯æ±‡ã€å·²è¦†ç›–è¯æ±‡ï¼‰
    3. è¿­ä»£è´ªå¿ƒé€‰æ‹©ï¼š
       - ä¸ºæ¯æœ¬å€™é€‰ä¹¦è®¡ç®—è¯„åˆ†
       - é€‰æ‹©å¾—åˆ†æœ€é«˜çš„ä¹¦
       - æ›´æ–°çŠ¶æ€
       - æ£€æŸ¥ç»ˆæ­¢æ¡ä»¶
    """
    
    # ç¬¬ä¸€æ­¥ï¼šå€™é€‰ç­›é€‰
    filtered_candidates = self._filter_candidates(
        candidates, books_analysis, target_level, 
        selection_criteria, already_selected_books
    )
    
    if not filtered_candidates:
        return self._empty_result()
    
    # ç¬¬äºŒæ­¥ï¼šåˆå§‹åŒ–çŠ¶æ€
    level_target_vocab = target_vocabulary.get(target_level, set())
    remaining_words = level_target_vocab - already_covered
    newly_covered = set()
    selected_books = []
    
    print(f"ç›®æ ‡è¯æ±‡: {len(level_target_vocab)}, "
          f"å·²è¦†ç›–: {len(already_covered & level_target_vocab)}, "
          f"å¾…è¦†ç›–: {len(remaining_words)}")
    
    # ç¬¬ä¸‰æ­¥ï¼šè¿­ä»£è´ªå¿ƒé€‰æ‹©
    iteration = 0
    while (len(selected_books) < max_books and 
           len(newly_covered) / len(level_target_vocab) < target_coverage and
           remaining_words and filtered_candidates):
        
        iteration += 1
        
        # ğŸŒŸ æ ¸å¿ƒï¼šé€‰æ‹©å½“å‰æœ€ä¼˜ä¹¦ç±
        best_book = self._select_best_book(
            filtered_candidates, books_analysis, 
            target_level, remaining_words, iteration
        )
        
        if best_book is None:
            break  # æ²¡æœ‰åˆé€‚çš„ä¹¦ç±äº†
        
        # æ›´æ–°çŠ¶æ€
        selected_books.append(best_book)
        filtered_candidates.remove(best_book)
        
        # è®¡ç®—æ–°è¦†ç›–çš„è¯æ±‡
        book_analysis = books_analysis[best_book]
        if target_level in book_analysis.level_distributions:
            new_words = (book_analysis.level_distributions[target_level].words 
                        & remaining_words)
            newly_covered.update(new_words)
            remaining_words -= new_words
            
            print(f"  é€‰æ‹©: {best_book}")
            print(f"  æ–°å¢{target_level}è¯æ±‡: {len(new_words)}")
            print(f"  å½“å‰è¦†ç›–ç‡: {len(newly_covered) / len(level_target_vocab):.1%}")
    
    return LevelSelectionResult(...)
```

## ğŸ“Š è¯„åˆ†æœºåˆ¶ï¼šé‡åŒ–ä¹¦ç±ä»·å€¼

### å¤šç»´åº¦è¯„åˆ†æ¨¡å‹

ä¹¦ç±è¯„åˆ†æ˜¯è´ªå¿ƒç®—æ³•çš„**å†³ç­–æ ¸å¿ƒ**ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªå¤šç»´åº¦è¯„åˆ†æ¨¡å‹ï¼š

```python
def calculate_book_score(self, book_analysis, target_level, remaining_words, iteration):
    """
    ä¹¦ç±è¯„åˆ†ï¼šå¤šç»´åº¦ä»·å€¼é‡åŒ–
    
    è¯„åˆ†ç»´åº¦ï¼š
    1. æ–°è¯æ±‡è¦†ç›–ï¼ˆä¸»è¦ä»·å€¼ï¼‰
    2. å¤ä¹ ä»·å€¼ï¼ˆä½çº§åˆ«è¯æ±‡ï¼‰
    3. é¢„ä¹ ä»·å€¼ï¼ˆé«˜çº§åˆ«è¯æ±‡ï¼‰
    4. éš¾åº¦æƒ©ç½šï¼ˆè¶…çº²è¯æ±‡ï¼‰
    5. æ•ˆç‡å¥–åŠ±ï¼ˆåæœŸè¿­ä»£ï¼‰
    """
    
    if target_level not in book_analysis.level_distributions:
        return -1.0  # æ— ç›¸å…³å†…å®¹ï¼Œç›´æ¥æ’é™¤
    
    target_level_stats = book_analysis.level_distributions[target_level]
    new_coverage = len(target_level_stats.words & remaining_words)
    
    if new_coverage == 0:
        return -1.0  # æ— æ–°ä»·å€¼ï¼Œæ’é™¤
    
    # ğŸ¯ æ ¸å¿ƒä»·å€¼ï¼šæ–°è¯æ±‡è¦†ç›–
    score = new_coverage * 10
    
    # ğŸ’ª å¤ä¹ ä»·å€¼ï¼šå·©å›ºå·²å­¦çŸ¥è¯†
    target_idx = self.level_manager.get_level_index(target_level)
    for i in range(target_idx):
        lower_level = self.config.levels[i]
        if lower_level in book_analysis.level_distributions:
            review_bonus = book_analysis.level_distributions[lower_level].count * 0.5
            score += review_bonus
    
    # ğŸ”® é¢„ä¹ ä»·å€¼ï¼šé€‚åº¦è¶…å‰å­¦ä¹ 
    if target_idx < len(self.config.levels) - 1:
        next_level = self.config.levels[target_idx + 1]
        if next_level in book_analysis.level_distributions:
            preview_count = book_analysis.level_distributions[next_level].count
            preview_bonus = min(preview_count, 100) * 0.1  # è®¾ç½®ä¸Šé™ï¼Œé¿å…è¿‡åº¦è¶…å‰
            score += preview_bonus
    
    # ğŸ’¥ éš¾åº¦æƒ©ç½šï¼šæ§åˆ¶å­¦ä¹ è´Ÿæ‹…
    unknown_penalty = book_analysis.unknown_count * 0.8
    score -= unknown_penalty
    
    # âš¡ æ•ˆç‡å¥–åŠ±ï¼šåæœŸæ›´æ³¨é‡æ•ˆç‡
    if iteration > 2 and remaining_words:
        efficiency_ratio = new_coverage / len(remaining_words)
        efficiency_bonus = efficiency_ratio * 50
        score += efficiency_bonus
    
    return score
```

### è¯„åˆ†ç­–ç•¥çš„æ™ºæ…§

#### ä»·å€¼é€’å‡åŸç†

```python
# ç¤ºä¾‹ï¼šB1çº§åˆ«ç¬¬3è½®é€‰æ‹©
remaining_words = {"government", "environment", "situation", "development"}

# å€™é€‰ä¹¦Aï¼šè¦†ç›–{"government", "environment"} - 50%å‰©ä½™è¯æ±‡
score_A = 2 * 10 + efficiency_bonus(0.5) = 20 + 25 = 45

# å€™é€‰ä¹¦Bï¼šè¦†ç›–{"situation"} - 25%å‰©ä½™è¯æ±‡  
score_B = 1 * 10 + efficiency_bonus(0.25) = 10 + 12.5 = 22.5

# ç®—æ³•é€‰æ‹©ä¹¦Aï¼šé«˜è¦†ç›–ç‡åœ¨åæœŸæ›´æœ‰ä»·å€¼
```

#### å¹³è¡¡æœºåˆ¶

```python
# é˜²æ­¢è¿‡åº¦åå‘æŸä¸€ç»´åº¦
def balanced_score(new_coverage, review_value, preview_value, difficulty_penalty):
    """å¹³è¡¡å„ç»´åº¦è´¡çŒ®"""
    
    # ä¸»è¦ä»·å€¼ï¼ˆ50%æƒé‡ï¼‰
    primary = new_coverage * 10
    
    # è¾…åŠ©ä»·å€¼ï¼ˆ30%æƒé‡ï¼‰
    secondary = (review_value + preview_value) * 0.6
    
    # éš¾åº¦æ§åˆ¶ï¼ˆ20%æƒé‡ï¼‰
    penalty = difficulty_penalty * 1.2
    
    return primary + secondary - penalty
```

## ğŸ”„ å€™é€‰ç­›é€‰ï¼šè´¨é‡é—¨æ§

### å¤šé‡ç­›é€‰æ¡ä»¶

```python
def _filter_candidates(self, candidates, books_analysis, target_level, 
                      criteria, already_selected_books):
    """
    å€™é€‰ç­›é€‰ï¼šå¤šé‡è´¨é‡é—¨æ§
    
    ç­›é€‰æ¡ä»¶ï¼š
    1. å…¨å±€å»é‡ï¼šé¿å…é‡å¤é€‰æ‹©
    2. è¶…çº²è¯æ§åˆ¶ï¼šç¡®ä¿éš¾åº¦é€‚å®œ
    3. é€‚åˆåº¦è¦æ±‚ï¼šç¡®ä¿ç›¸å…³æ€§
    4. æœ€ä½è¯æ±‡é‡ï¼šç¡®ä¿å­¦ä¹ ä»·å€¼
    """
    
    filtered = []
    
    for book_id in candidates:
        # é—¨æ§1ï¼šå…¨å±€å»é‡
        if book_id in already_selected_books:
            continue
        
        analysis = books_analysis[book_id]
        
        # é—¨æ§2ï¼šè¶…çº²è¯æ§åˆ¶
        if analysis.unknown_ratio > criteria.max_unknown_ratio:
            continue  # å¤ªéš¾äº†ï¼Œè·³è¿‡
        
        # é—¨æ§3ï¼šé€‚åˆåº¦è¦æ±‚
        suitability = analysis.suitability_scores.get(target_level, 0.0)
        if suitability < criteria.min_suitability_score:
            continue  # ä¸å¤Ÿç›¸å…³ï¼Œè·³è¿‡
        
        # é—¨æ§4ï¼šæœ€ä½è¯æ±‡é‡
        if target_level in analysis.level_distributions:
            target_word_count = analysis.level_distributions[target_level].count
            if target_word_count >= criteria.min_target_words:
                filtered.append(book_id)
    
    # é¢„æ’åºï¼šæŒ‰å­¦ä¹ ä»·å€¼é™åºæ’åˆ—
    filtered.sort(key=lambda x: books_analysis[x].learning_value, reverse=True)
    
    print(f"  {target_level}ç­‰çº§å€™é€‰ä¹¦ç±: {len(filtered)}æœ¬")
    return filtered
```

### è‡ªé€‚åº”ç­›é€‰ç­–ç•¥

```python
def adaptive_filtering(self, candidates, target_level, iteration):
    """æ ¹æ®è¿­ä»£è½®æ¬¡è‡ªé€‚åº”è°ƒæ•´ç­›é€‰æ¡ä»¶"""
    
    base_criteria = self.default_criteria
    
    if iteration == 1:
        # ç¬¬ä¸€è½®ï¼šä¸¥æ ¼ç­›é€‰ï¼Œç¡®ä¿é«˜è´¨é‡
        return base_criteria.model_copy(update={
            "max_unknown_ratio": base_criteria.max_unknown_ratio * 0.8,
            "min_suitability_score": base_criteria.min_suitability_score * 1.2,
            "min_target_words": base_criteria.min_target_words * 1.5
        })
    elif iteration >= 3:
        # åæœŸè½®æ¬¡ï¼šæ”¾å®½æ¡ä»¶ï¼Œç¡®ä¿èƒ½æ‰¾åˆ°å€™é€‰
        return base_criteria.model_copy(update={
            "max_unknown_ratio": base_criteria.max_unknown_ratio * 1.3,
            "min_suitability_score": base_criteria.min_suitability_score * 0.7,
            "min_target_words": base_criteria.min_target_words * 0.5
        })
    else:
        # ä¸­æœŸï¼šä½¿ç”¨æ ‡å‡†æ¡ä»¶
        return base_criteria
```

## ğŸ“ˆ ç®—æ³•æ€§èƒ½åˆ†æ

### æ—¶é—´å¤æ‚åº¦

```text
ä¸»ç®—æ³•ï¼šcreate_progressive_reading_path
â”œâ”€â”€ å¤–å±‚å¾ªç¯ï¼šMä¸ªçº§åˆ« - O(M)
â””â”€â”€ å†…å±‚å¾ªç¯ï¼šselect_books_for_level
    â”œâ”€â”€ å€™é€‰ç­›é€‰ï¼šO(N) 
    â”œâ”€â”€ è´ªå¿ƒé€‰æ‹©è¿­ä»£ï¼šæœ€å¤škè½®
    â”‚   â”œâ”€â”€ æ¯è½®è¯„åˆ†ï¼šO(N)
    â”‚   â””â”€â”€ æœ€ä¼˜é€‰æ‹©ï¼šO(N)
    â””â”€â”€ æ€»è®¡ï¼šO(kÃ—N)

æ€»ä½“å¤æ‚åº¦ï¼šO(MÃ—kÃ—N)

å…¶ä¸­ï¼š
- Mï¼šçº§åˆ«æ•°é‡ï¼ˆé€šå¸¸5-10ï¼‰
- Nï¼šä¹¦ç±æ€»æ•°ï¼ˆé€šå¸¸100-10000ï¼‰  
- kï¼šæ¯çº§åˆ«æœ€å¤§ä¹¦ç±æ•°ï¼ˆé€šå¸¸2-5ï¼‰

å®é™…å¤æ‚åº¦ï¼šO(N) - è¿‘ä¼¼çº¿æ€§ï¼
```

### ç©ºé—´å¤æ‚åº¦

```text
ä¸»è¦å­˜å‚¨ï¼š
â”œâ”€â”€ ä¹¦ç±åˆ†æç»“æœï¼šO(NÃ—V) - Næœ¬ä¹¦ï¼Œæ¯æœ¬Vä¸ªè¯æ±‡
â”œâ”€â”€ ç›®æ ‡è¯æ±‡é›†åˆï¼šO(MÃ—W) - Mä¸ªçº§åˆ«ï¼Œæ¯çº§åˆ«Wä¸ªè¯æ±‡
â”œâ”€â”€ ç´¯ç§¯çŠ¶æ€ï¼šO(Total_Words) - ç´¯ç§¯è¦†ç›–çš„è¯æ±‡
â””â”€â”€ ä¸­é—´ç»“æœï¼šO(MÃ—k) - æ¯çº§åˆ«é€‰æ‹©kæœ¬ä¹¦

æ€»ä½“ï¼šO(NÃ—V + MÃ—W) - ä¸»è¦å—ä¹¦ç±æ•°é‡å’Œè¯æ±‡é‡å½±å“
```

### æ€§èƒ½ä¼˜åŒ–æŠ€å·§

#### 1. é¢„è®¡ç®—ä¼˜åŒ–

```python
class OptimizedPathGenerator(GenericPathGenerator):
    """æ€§èƒ½ä¼˜åŒ–ç‰ˆè·¯å¾„ç”Ÿæˆå™¨"""
    
    def __init__(self, config):
        super().__init__(config)
        self._score_cache = {}  # è¯„åˆ†ç¼“å­˜
        self._filter_cache = {}  # ç­›é€‰ç¼“å­˜
    
    def calculate_book_score(self, book_analysis, target_level, remaining_words, iteration):
        # ç”Ÿæˆç¼“å­˜é”®
        remaining_hash = hash(frozenset(remaining_words))
        cache_key = (book_analysis.book_id, target_level, remaining_hash, iteration)
        
        if cache_key in self._score_cache:
            return self._score_cache[cache_key]
        
        score = super().calculate_book_score(book_analysis, target_level, remaining_words, iteration)
        self._score_cache[cache_key] = score
        return score
```

#### 2. å¹¶è¡Œè®¡ç®—ä¼˜åŒ–

```python
def parallel_book_scoring(self, candidates, target_level, remaining_words, iteration):
    """å¹¶è¡Œè®¡ç®—å€™é€‰ä¹¦ç±è¯„åˆ†"""
    
    from concurrent.futures import ThreadPoolExecutor
    
    def score_single_book(book_id):
        analysis = self.books_analysis[book_id]
        score = self.calculate_book_score(analysis, target_level, remaining_words, iteration)
        return book_id, score
    
    with ThreadPoolExecutor(max_workers=4) as executor:
        results = list(executor.map(score_single_book, candidates))
    
    return results
```

## ğŸ¯ ç®—æ³•è°ƒä¼˜ç­–ç•¥

### å‚æ•°æ•æ„Ÿæ€§åˆ†æ

ä¸åŒå‚æ•°å¯¹ç»“æœçš„å½±å“ï¼š

```python
def parameter_sensitivity_analysis(self, base_params):
    """å‚æ•°æ•æ„Ÿæ€§åˆ†æ"""
    
    results = {}
    
    # æµ‹è¯•è¦†ç›–ç‡ç›®æ ‡çš„å½±å“
    for coverage in [0.7, 0.8, 0.85, 0.9, 0.95]:
        modified_params = base_params.model_copy(update={
            "target_coverage_per_level": {level: coverage for level in self.config.levels}
        })
        result = self.create_progressive_reading_path(..., modified_params)
        results[f"coverage_{coverage}"] = {
            "total_books": len(result.total_books),
            "final_coverage": result.summary["final_coverage"],
            "difficulty_progression": result.summary["difficulty_progression"]
        }
    
    # æµ‹è¯•æœ€å¤§ä¹¦ç±æ•°çš„å½±å“
    for max_books in [2, 3, 4, 5]:
        modified_params = base_params.model_copy(update={
            "max_books_per_level": {level: max_books for level in self.config.levels}
        })
        result = self.create_progressive_reading_path(..., modified_params)
        results[f"max_books_{max_books}"] = {...}
    
    return results
```

### A/Bæµ‹è¯•æ¡†æ¶

```python
def compare_algorithm_variants(self, variant_configs):
    """æ¯”è¾ƒä¸åŒç®—æ³•é…ç½®çš„æ•ˆæœ"""
    
    results = {}
    
    for variant_name, config in variant_configs.items():
        # ä½¿ç”¨ç›¸åŒæ•°æ®æµ‹è¯•ä¸åŒé…ç½®
        generator = GenericPathGenerator(config)
        result = generator.create_progressive_reading_path(...)
        
        # è¯„ä¼°æŒ‡æ ‡
        metrics = {
            "coverage_efficiency": self._calculate_coverage_efficiency(result),
            "difficulty_smoothness": self._calculate_difficulty_smoothness(result),
            "learning_value_density": self._calculate_learning_value_density(result),
            "path_coherence": self._calculate_path_coherence(result)
        }
        
        results[variant_name] = {
            "path_result": result,
            "metrics": metrics
        }
    
    return results
```

## ğŸ¯ å®è·µç»ƒä¹ 

### ç»ƒä¹ 1ï¼šç®—æ³•æ”¹è¿›

å°è¯•å®ç°ä»¥ä¸‹ç®—æ³•æ”¹è¿›ï¼š

1. **å¤šæ ·æ€§ä¼˜åŒ–**ï¼šé¿å…é€‰æ‹©å†…å®¹è¿‡äºç›¸ä¼¼çš„ä¹¦ç±
2. **åŠ¨æ€æƒé‡è°ƒæ•´**ï¼šæ ¹æ®å­¦ä¹ è¿›åº¦è°ƒæ•´è¯„åˆ†æƒé‡
3. **å›æº¯æœºåˆ¶**ï¼šå…è®¸æ’¤é”€ä¸è‰¯é€‰æ‹©ï¼Œé‡æ–°é€‰æ‹©
4. **å¤šç›®æ ‡ä¼˜åŒ–**ï¼šåŒæ—¶ä¼˜åŒ–è¦†ç›–ç‡ã€éš¾åº¦å¹³æ»‘æ€§å’Œå­¦ä¹ ä»·å€¼

### ç»ƒä¹ 2ï¼šè¯„åˆ†å‡½æ•°è®¾è®¡

è®¾è®¡ä¸“é—¨çš„è¯„åˆ†å‡½æ•°ï¼š

1. **æ—¶é—´æ•æ„Ÿè¯„åˆ†**ï¼šè€ƒè™‘å­¦ä¹ æ—¶é—´æˆæœ¬
2. **å…´è¶£å¯¼å‘è¯„åˆ†**ï¼šåŸºäºå­¦ä¹ è€…å…´è¶£åå¥½
3. **è®°å¿†ä¼˜åŒ–è¯„åˆ†**ï¼šåŸºäºè®°å¿†æ›²çº¿å’Œé—å¿˜è§„å¾‹
4. **æŠ€èƒ½å¯¼å‘è¯„åˆ†**ï¼šé’ˆå¯¹ç‰¹å®šæŠ€èƒ½çš„è¯æ±‡æƒé‡

### ç»ƒä¹ 3ï¼šç®—æ³•å¯è§†åŒ–

å®ç°ç®—æ³•è¿‡ç¨‹çš„å¯è§†åŒ–ï¼š

1. **å†³ç­–æ ‘å¯è§†åŒ–**ï¼šå±•ç¤ºæ¯ä¸€æ­¥çš„å†³ç­–è¿‡ç¨‹
2. **è¯„åˆ†çƒ­åŠ›å›¾**ï¼šå±•ç¤ºä¹¦ç±è¯„åˆ†çš„åˆ†å¸ƒ
3. **è¦†ç›–ç‡è¿›å±•å›¾**ï¼šå±•ç¤ºè¯æ±‡è¦†ç›–çš„å¢é•¿æ›²çº¿
4. **ç®—æ³•æ”¶æ•›å›¾**ï¼šå±•ç¤ºç®—æ³•çš„æ”¶æ•›è¿‡ç¨‹

## ğŸ”„ ä¸‹ä¸€æ­¥é¢„å‘Š

ç®—æ³•æ˜¯ç†è®ºï¼Œåº”ç”¨æ˜¯å®è·µã€‚åœ¨ä¸‹ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å°†é€šè¿‡**ä¸°å¯Œçš„å®ç°ç¤ºä¾‹**ï¼Œçœ‹çœ‹è¿™äº›ç®—æ³•å¦‚ä½•åœ¨çœŸå®åœºæ™¯ä¸­å‘æŒ¥ä½œç”¨ï¼ŒåŒ…æ‹¬ï¼š

- CEFRæ ‡å‡†é…ç½®çš„æœ€ä½³å®è·µ
- K-12å¹´çº§åˆ¶ç³»ç»Ÿçš„å®Œæ•´å®ç°
- ä¸“ä¸šé¢†åŸŸè¯æ±‡è·¯å¾„çš„è®¾è®¡æŠ€å·§
- å¤šç§å­¦ä¹ ç­–ç•¥çš„å¯¹æ¯”åˆ†æ

**æ€è€ƒé¢˜**ï¼š

1. å¦‚ä½•è®¾è®¡ç®—æ³•æ¥å¤„ç†ä¹¦ç±ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼ˆå¦‚ç³»åˆ—ä¸›ä¹¦ï¼‰ï¼Ÿ
2. è´ªå¿ƒç®—æ³•åœ¨ä»€ä¹ˆæƒ…å†µä¸‹å¯èƒ½äº§ç”Ÿæ¬¡ä¼˜è§£ï¼Ÿå¦‚ä½•æ£€æµ‹å’Œæ”¹è¿›ï¼Ÿ
3. å¦‚ä½•å°†ç”¨æˆ·åé¦ˆæ•´åˆåˆ°ç®—æ³•ä¸­ï¼Œå®ç°è‡ªé€‚åº”ä¼˜åŒ–ï¼Ÿ

è®©æˆ‘ä»¬åœ¨å®è·µä¸­è§è¯ç®—æ³•çš„å¨åŠ›ï¼

---

> "The algorithm is the soul of the system - it embodies the wisdom of countless decisions, distilled into elegant mathematical logic."
> "ç®—æ³•æ˜¯ç³»ç»Ÿçš„çµé­‚â€”â€”å®ƒä½“ç°äº†æ— æ•°å†³ç­–çš„æ™ºæ…§ï¼Œæç‚¼æˆä¼˜é›…çš„æ•°å­¦é€»è¾‘ã€‚"

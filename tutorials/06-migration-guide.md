# 06. è¿ç§»ä¸é›†æˆæŒ‡å—ï¼šä»CEFRåˆ°é€šç”¨ç³»ç»Ÿçš„å¹³æ»‘è¿‡æ¸¡

> *"æœ€å¥½çš„è¿ç§»æ˜¯è®©ç”¨æˆ·æ„Ÿè§‰ä¸åˆ°å˜åŒ–ï¼ŒåŒæ—¶äº«å—åˆ°æ‰€æœ‰æ–°åŠŸèƒ½çš„å¥½å¤„ã€‚"*

## ğŸ¯ è¿ç§»æ¦‚è¿°

### ä¸ºä»€ä¹ˆéœ€è¦è¿ç§»ï¼Ÿ

å¦‚æœä½ æ­£åœ¨ä½¿ç”¨åŸå§‹çš„`LayeredCEFRBookSelector`ï¼Œä½ å¯èƒ½é‡åˆ°ä»¥ä¸‹ç—›ç‚¹ï¼š

1. **åŠŸèƒ½å±€é™**ï¼šåªæ”¯æŒCEFRç­‰çº§ï¼Œæ— æ³•é€‚åº”å…¶ä»–åˆ†çº§ç³»ç»Ÿ
2. **æ‰©å±•å›°éš¾**ï¼šæ·»åŠ æ–°åŠŸèƒ½éœ€è¦ä¿®æ”¹æ ¸å¿ƒä»£ç 
3. **ç±»å‹å®‰å…¨ç¼ºå¤±**ï¼šé…ç½®é”™è¯¯åªèƒ½åœ¨è¿è¡Œæ—¶å‘ç°
4. **æ€§èƒ½ç“¶é¢ˆ**ï¼šå¤§æ•°æ®é›†å¤„ç†æ•ˆç‡ä¸é«˜
5. **ç»´æŠ¤å¤æ‚**ï¼šä»£ç è€¦åˆåº¦é«˜ï¼Œéš¾ä»¥æµ‹è¯•å’Œè°ƒè¯•

é€šç”¨è¯æ±‡è·¯å¾„æ„å»ºå™¨è§£å†³äº†è¿™äº›é—®é¢˜ï¼ŒåŒæ—¶ä¿æŒäº†å‘åå…¼å®¹æ€§ã€‚

### è¿ç§»ç­–ç•¥

æˆ‘ä»¬æä¾›ä¸‰ç§è¿ç§»ç­–ç•¥ï¼š

1. **ğŸŸ¢ å³æ’å³ç”¨è¿ç§»**ï¼šæœ€å°ä»£ç ä¿®æ”¹ï¼Œç«‹å³äº«å—æ–°åŠŸèƒ½
2. **ğŸŸ¡ æ¸è¿›å¼è¿ç§»**ï¼šåˆ†é˜¶æ®µè¿ç§»ï¼Œé€æ­¥åˆ©ç”¨æ–°ç‰¹æ€§
3. **ğŸ”´ å®Œå…¨é‡æ„è¿ç§»**ï¼šå……åˆ†åˆ©ç”¨æ–°æ¶æ„çš„æ‰€æœ‰ä¼˜åŠ¿

## ğŸ”„ å³æ’å³ç”¨è¿ç§»ï¼ˆæ¨èå¼€å§‹æ–¹å¼ï¼‰

### åŸå§‹ä»£ç 

```python
# åŸå§‹CEFRç³»ç»Ÿä»£ç 
from reading_path_builder import LayeredCEFRBookSelector

# åˆ›å»ºé€‰æ‹©å™¨
selector = LayeredCEFRBookSelector(books_vocab, vocab_levels)

# ç”Ÿæˆè·¯å¾„
path = selector.create_progressive_reading_path()

# æ‰“å°ç»“æœ
selector.print_reading_path(path)

# è¯„ä¼°ä¹¦ç±
book_eval = selector.evaluate_book_difficulty("book_123")
```

### è¿ç§»åä»£ç 

```python
# è¿ç§»åˆ°é€šç”¨ç³»ç»Ÿ
from generic_vocabulary_path_builder import (
    LayeredVocabularyPathBuilder, 
    VocabularyLevelConfig
)

# æ­¥éª¤1ï¼šåˆ›å»ºCEFRé…ç½®ï¼ˆä¸€è¡Œä»£ç ï¼ï¼‰
cefr_config = VocabularyLevelConfig.create_cefr_config()

# æ­¥éª¤2ï¼šåˆ›å»ºé€šç”¨æ„å»ºå™¨
builder = LayeredVocabularyPathBuilder(
    books_vocab=books_vocab,
    vocab_level_mapping=vocab_levels,  # å‚æ•°åç¨æœ‰å˜åŒ–
    level_config=cefr_config
)

# æ­¥éª¤3ï¼šç”Ÿæˆè·¯å¾„ï¼ˆAPIä¿æŒä¸€è‡´ï¼‰
path = builder.create_reading_path()

# æ­¥éª¤4ï¼šæ‰“å°ç»“æœï¼ˆå®Œå…¨å…¼å®¹ï¼‰
builder.print_reading_path(path)

# æ­¥éª¤5ï¼šè¯„ä¼°ä¹¦ç±ï¼ˆå¢å¼ºç‰ˆAPIï¼‰
book_eval = builder.evaluate_book_for_level("book_123", "B1")
```

### å…³é”®å˜åŒ–æ€»ç»“

| åŸå§‹API | æ–°API | å˜åŒ–è¯´æ˜ |
|---------|-------|----------|
| `LayeredCEFRBookSelector(books, vocab)` | `LayeredVocabularyPathBuilder(books, vocab, config)` | å¢åŠ é…ç½®å‚æ•° |
| `vocab_levels` | `vocab_level_mapping` | å‚æ•°åæ›´æ˜ç¡® |
| `create_progressive_reading_path()` | `create_reading_path()` | æ–¹æ³•åç®€åŒ– |
| `evaluate_book_difficulty(book_id)` | `evaluate_book_for_level(book_id, level)` | å¢åŠ çº§åˆ«å‚æ•° |

## ğŸŸ¡ æ¸è¿›å¼è¿ç§»

### ç¬¬ä¸€é˜¶æ®µï¼šä¿æŒåŸæœ‰åŠŸèƒ½

```python
def migrate_phase_1():
    """ç¬¬ä¸€é˜¶æ®µï¼šåŸºæœ¬è¿ç§»ï¼Œä¿æŒåŸæœ‰åŠŸèƒ½"""
    
    # ä½¿ç”¨å·¥å‚æ–¹æ³•ç¡®ä¿å®Œå…¨å…¼å®¹
    cefr_config = VocabularyLevelConfig.create_cefr_config()
    
    # åˆ›å»ºæ„å»ºå™¨
    builder = LayeredVocabularyPathBuilder(
        books_vocab=load_books_data(),
        vocab_level_mapping=load_vocab_mapping(),
        level_config=cefr_config
    )
    
    # ä½¿ç”¨é»˜è®¤å‚æ•°ï¼Œè¡Œä¸ºä¸åŸç³»ç»Ÿä¸€è‡´
    path = builder.create_reading_path()
    
    return builder, path

# éªŒè¯è¿ç§»æ•ˆæœ
def verify_migration():
    """éªŒè¯è¿ç§»æ˜¯å¦æˆåŠŸ"""
    
    # åŸå§‹ç³»ç»Ÿç»“æœ
    old_selector = LayeredCEFRBookSelector(books_vocab, vocab_levels)
    old_path = old_selector.create_progressive_reading_path()
    
    # æ–°ç³»ç»Ÿç»“æœ
    new_builder, new_path = migrate_phase_1()
    
    # æ¯”è¾ƒå…³é”®æŒ‡æ ‡
    old_books = old_path.get("total_books", [])
    new_books = new_path.total_books
    
    print(f"åŸç³»ç»Ÿä¹¦ç±æ•°: {len(old_books)}")
    print(f"æ–°ç³»ç»Ÿä¹¦ç±æ•°: {len(new_books)}")
    
    # æ£€æŸ¥ä¹¦ç±é€‰æ‹©æ˜¯å¦ä¸€è‡´ï¼ˆå…è®¸å°å¹…å·®å¼‚ï¼‰
    overlap = set(old_books) & set(new_books)
    overlap_ratio = len(overlap) / max(len(old_books), len(new_books))
    
    print(f"ä¹¦ç±é‡å ç‡: {overlap_ratio:.1%}")
    
    if overlap_ratio >= 0.8:
        print("âœ… è¿ç§»æˆåŠŸï¼ç»“æœé«˜åº¦ä¸€è‡´")
    elif overlap_ratio >= 0.6:
        print("âš ï¸ è¿ç§»åŸºæœ¬æˆåŠŸï¼Œå­˜åœ¨å°å¹…ä¼˜åŒ–")
    else:
        print("âŒ è¿ç§»å­˜åœ¨é—®é¢˜ï¼Œéœ€è¦è°ƒæŸ¥")
```

### ç¬¬äºŒé˜¶æ®µï¼šåˆ©ç”¨æ–°ç‰¹æ€§

```python
def migrate_phase_2():
    """ç¬¬äºŒé˜¶æ®µï¼šå¼€å§‹åˆ©ç”¨æ–°ç‰¹æ€§"""
    
    # åŸºç¡€é…ç½®
    cefr_config = VocabularyLevelConfig.create_cefr_config()
    builder = LayeredVocabularyPathBuilder(
        books_vocab=books_vocab,
        vocab_level_mapping=vocab_levels,
        level_config=cefr_config
    )
    
    # ğŸŒŸ æ–°ç‰¹æ€§1ï¼šå¤šç­–ç•¥ç”Ÿæˆ
    strategies = builder.get_alternative_paths(["conservative", "standard", "fast"])
    
    print("ğŸ“Š å¤šç­–ç•¥å¯¹æ¯”:")
    for strategy_name, path_result in strategies:
        total_books = len(path_result.total_books)
        print(f"  {strategy_name}: {total_books}æœ¬ä¹¦")
    
    # ğŸŒŸ æ–°ç‰¹æ€§2ï¼šè¯¦ç»†ä¹¦ç±è¯„ä¼°
    sample_books = list(books_vocab.keys())[:5]
    
    print("\nğŸ“– è¯¦ç»†ä¹¦ç±è¯„ä¼°:")
    for book_id in sample_books:
        for level in ["A2", "B1", "B2"]:
            eval_result = builder.evaluate_book_for_level(book_id, level)
            suitability = eval_result.suitability_score
            print(f"  {book_id} â†’ {level}: {suitability:.1%}")
    
    # ğŸŒŸ æ–°ç‰¹æ€§3ï¼šç»Ÿè®¡ä¿¡æ¯è·å–
    vocab_stats = builder.get_level_vocabulary_stats()
    print(f"\nğŸ“ˆ è¯æ±‡ç»Ÿè®¡: {vocab_stats}")
    
    return builder

def migrate_phase_3():
    """ç¬¬ä¸‰é˜¶æ®µï¼šå‚æ•°ä¼˜åŒ–"""
    
    cefr_config = VocabularyLevelConfig.create_cefr_config()
    builder = LayeredVocabularyPathBuilder(books_vocab, vocab_levels, cefr_config)
    
    # ğŸŒŸ æ–°ç‰¹æ€§4ï¼šè‡ªå®šä¹‰å‚æ•°
    from generic_vocabulary_path_builder import PathGenerationParameters
    
    # ä¸ºæ—¶é—´ç´§å¼ çš„å­¦ä¹ è€…ä¼˜åŒ–
    fast_params = PathGenerationParameters(
        max_books_per_level={"A1": 2, "A2": 2, "B1": 3, "B2": 2, "C1": 2},
        target_coverage_per_level={"A1": 0.8, "A2": 0.85, "B1": 0.85, "B2": 0.8, "C1": 0.75},
        max_unknown_ratio=0.20,
        min_relevant_ratio=0.35
    )
    
    fast_path = builder.create_reading_path(fast_params)
    builder.print_reading_path(fast_path, "å¿«é€Ÿå­¦ä¹ è·¯å¾„")
    
    return builder
```

## ğŸ”´ å®Œå…¨é‡æ„è¿ç§»

### æ•°æ®æ¨¡å‹å‡çº§

```python
def complete_migration_with_data_models():
    """å®Œå…¨è¿ç§»ï¼šå……åˆ†åˆ©ç”¨æ–°çš„æ•°æ®æ¨¡å‹"""
    
    # æ­¥éª¤1ï¼šå‡çº§é…ç½®ç®¡ç†
    config_manager = create_advanced_config_manager()
    
    # æ­¥éª¤2ï¼šä½¿ç”¨ç»“æ„åŒ–æ•°æ®æ¨¡å‹
    book_analyses = precompute_book_analyses()
    
    # æ­¥éª¤3ï¼šå®ç°é«˜çº§è·¯å¾„ç”Ÿæˆ
    advanced_builder = create_advanced_builder(config_manager, book_analyses)
    
    # æ­¥éª¤4ï¼šé›†æˆå¤–éƒ¨ç³»ç»Ÿ
    integrated_system = integrate_with_external_systems(advanced_builder)
    
    return integrated_system

def create_advanced_config_manager():
    """åˆ›å»ºé«˜çº§é…ç½®ç®¡ç†å™¨"""
    
    class AdvancedConfigManager:
        def __init__(self):
            self.configs = {
                "cefr_standard": VocabularyLevelConfig.create_cefr_config(),
                "cefr_conservative": self._create_conservative_cefr(),
                "cefr_aggressive": self._create_aggressive_cefr()
            }
        
        def _create_conservative_cefr(self):
            base_config = VocabularyLevelConfig.create_cefr_config()
            return base_config.model_copy(update={
                "weights": {"A1": 2.0, "A2": 1.8, "B1": 1.5, "B2": 1.2, "C1": 1.0}
            })
        
        def _create_aggressive_cefr(self):
            base_config = VocabularyLevelConfig.create_cefr_config()
            return base_config.model_copy(update={
                "weights": {"A1": 1.2, "A2": 1.1, "B1": 1.0, "B2": 1.2, "C1": 1.5}
            })
        
        def get_config(self, config_name: str):
            return self.configs.get(config_name, self.configs["cefr_standard"])
        
        def create_custom_config(self, user_preferences: dict):
            """æ ¹æ®ç”¨æˆ·åå¥½åˆ›å»ºå®šåˆ¶é…ç½®"""
            base_config = self.configs["cefr_standard"]
            
            if user_preferences.get("focus", "") == "basic":
                return self.configs["cefr_conservative"]
            elif user_preferences.get("focus", "") == "advanced":
                return self.configs["cefr_aggressive"]
            else:
                return base_config
    
    return AdvancedConfigManager()

def precompute_book_analyses():
    """é¢„è®¡ç®—ä¹¦ç±åˆ†æç»“æœ"""
    
    from generic_vocabulary_path_builder import BookStatisticsCalculator
    
    # åˆ›å»ºåˆ†æè®¡ç®—å™¨
    config = VocabularyLevelConfig.create_cefr_config()
    calculator = BookStatisticsCalculator(config)
    calculator.set_vocabulary_mapping(vocab_levels)
    
    # æ‰¹é‡åˆ†ææ‰€æœ‰ä¹¦ç±
    book_analyses = {}
    
    print("ğŸ“Š é¢„è®¡ç®—ä¹¦ç±åˆ†æç»“æœ...")
    for book_id, book_vocab in books_vocab.items():
        analysis = calculator.calculate_book_analysis(book_id, book_vocab)
        book_analyses[book_id] = analysis
    
    print(f"âœ… å®Œæˆ {len(book_analyses)} æœ¬ä¹¦çš„åˆ†æ")
    
    # ä¿å­˜åˆ†æç»“æœï¼ˆå¯é€‰ï¼‰
    save_analyses_to_cache(book_analyses)
    
    return book_analyses

def save_analyses_to_cache(book_analyses):
    """ä¿å­˜åˆ†æç»“æœåˆ°ç¼“å­˜"""
    import json
    import pickle
    
    # æ–¹å¼1ï¼šJSONæ ¼å¼ï¼ˆå¯è¯»æ€§å¥½ï¼‰
    json_data = {}
    for book_id, analysis in book_analyses.items():
        json_data[book_id] = analysis.model_dump()
    
    with open("book_analyses_cache.json", "w", encoding="utf-8") as f:
        json.dump(json_data, f, indent=2, ensure_ascii=False)
    
    # æ–¹å¼2ï¼šPickleæ ¼å¼ï¼ˆæ€§èƒ½å¥½ï¼‰
    with open("book_analyses_cache.pkl", "wb") as f:
        pickle.dump(book_analyses, f)
    
    print("ğŸ’¾ åˆ†æç»“æœå·²ä¿å­˜åˆ°ç¼“å­˜")

def load_analyses_from_cache():
    """ä»ç¼“å­˜åŠ è½½åˆ†æç»“æœ"""
    import pickle
    
    try:
        with open("book_analyses_cache.pkl", "rb") as f:
            book_analyses = pickle.load(f)
        print(f"ğŸ“‚ ä»ç¼“å­˜åŠ è½½äº† {len(book_analyses)} æœ¬ä¹¦çš„åˆ†æç»“æœ")
        return book_analyses
    except FileNotFoundError:
        print("âš ï¸ ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨ï¼Œéœ€è¦é‡æ–°è®¡ç®—")
        return None
```

## ğŸ”§ è¿ç§»å·¥å…·ä¸è„šæœ¬

### è‡ªåŠ¨è¿ç§»è„šæœ¬

```python
def create_migration_script():
    """åˆ›å»ºè‡ªåŠ¨è¿ç§»è„šæœ¬"""
    
    migration_script = """
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
\"\"\"
è‡ªåŠ¨è¿ç§»è„šæœ¬ï¼šä»LayeredCEFRBookSelectorè¿ç§»åˆ°LayeredVocabularyPathBuilder
\"\"\"

import sys
import os
from pathlib import Path

def migrate_codebase(source_dir: str, backup_dir: str = None):
    \"\"\"è‡ªåŠ¨è¿ç§»ä»£ç åº“\"\"\"
    
    if backup_dir:
        create_backup(source_dir, backup_dir)
    
    # æŸ¥æ‰¾éœ€è¦è¿ç§»çš„Pythonæ–‡ä»¶
    python_files = list(Path(source_dir).rglob("*.py"))
    
    migration_count = 0
    
    for file_path in python_files:
        if migrate_file(file_path):
            migration_count += 1
    
    print(f"âœ… è¿ç§»å®Œæˆï¼å…±å¤„ç† {migration_count} ä¸ªæ–‡ä»¶")
    print("âš ï¸ è¯·æ‰‹åŠ¨æ£€æŸ¥å¹¶æµ‹è¯•è¿ç§»ç»“æœ")

def migrate_file(file_path: Path) -> bool:
    \"\"\"è¿ç§»å•ä¸ªæ–‡ä»¶\"\"\"
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        original_content = content
        
        # æ›¿æ¢å¯¼å…¥è¯­å¥
        content = content.replace(
            "from reading_path_builder import LayeredCEFRBookSelector",
            "from generic_vocabulary_path_builder import LayeredVocabularyPathBuilder, VocabularyLevelConfig"
        )
        
        # æ›¿æ¢ç±»å
        content = content.replace(
            "LayeredCEFRBookSelector(",
            "LayeredVocabularyPathBuilder("
        )
        
        # æ›¿æ¢æ–¹æ³•è°ƒç”¨
        content = content.replace(
            "create_progressive_reading_path(",
            "create_reading_path("
        )
        
        # å¦‚æœæœ‰å˜åŒ–ï¼Œå†™å›æ–‡ä»¶
        if content != original_content:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            print(f"ğŸ“ å·²è¿ç§»: {file_path}")
            return True
        
        return False
        
    except Exception as e:
        print(f"âŒ è¿ç§»å¤±è´¥ {file_path}: {e}")
        return False

def create_backup(source_dir: str, backup_dir: str):
    \"\"\"åˆ›å»ºå¤‡ä»½\"\"\"
    import shutil
    
    backup_path = Path(backup_dir)
    backup_path.mkdir(parents=True, exist_ok=True)
    
    shutil.copytree(source_dir, backup_path / "original_code", dirs_exist_ok=True)
    print(f"ğŸ“¦ å·²åˆ›å»ºå¤‡ä»½: {backup_path / 'original_code'}")

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python migrate.py <source_directory> [backup_directory]")
        sys.exit(1)
    
    source_dir = sys.argv[1]
    backup_dir = sys.argv[2] if len(sys.argv) > 2 else "backup"
    
    migrate_codebase(source_dir, backup_dir)
"""
    
    with open("migrate.py", "w", encoding="utf-8") as f:
        f.write(migration_script)
    
    print("ğŸ”§ å·²åˆ›å»ºè¿ç§»è„šæœ¬: migrate.py")
    print("ğŸ“‹ ä½¿ç”¨æ–¹æ³•: python migrate.py <source_directory> [backup_directory]")

# ç”Ÿæˆè¿ç§»è„šæœ¬
create_migration_script()
```

### å…¼å®¹æ€§éªŒè¯å·¥å…·

```python
def create_compatibility_validator():
    """åˆ›å»ºå…¼å®¹æ€§éªŒè¯å·¥å…·"""
    
    def validate_api_compatibility():
        """éªŒè¯APIå…¼å®¹æ€§"""
        
        print("ğŸ” APIå…¼å®¹æ€§éªŒè¯...")
        
        # æµ‹è¯•åŸºæœ¬åŠŸèƒ½
        try:
            # åˆ›å»ºæ–°ç³»ç»Ÿå®ä¾‹
            config = VocabularyLevelConfig.create_cefr_config()
            builder = LayeredVocabularyPathBuilder(books_vocab, vocab_levels, config)
            
            # æµ‹è¯•è·¯å¾„ç”Ÿæˆ
            path = builder.create_reading_path()
            assert hasattr(path, 'total_books'), "ç¼ºå°‘total_bookså±æ€§"
            assert hasattr(path, 'levels'), "ç¼ºå°‘levelså±æ€§"
            
            # æµ‹è¯•ä¹¦ç±è¯„ä¼°
            sample_book = list(books_vocab.keys())[0]
            evaluation = builder.evaluate_book_for_level(sample_book, "B1")
            assert hasattr(evaluation, 'suitability_score'), "ç¼ºå°‘suitability_scoreå±æ€§"
            
            print("âœ… APIå…¼å®¹æ€§éªŒè¯é€šè¿‡")
            return True
            
        except Exception as e:
            print(f"âŒ APIå…¼å®¹æ€§éªŒè¯å¤±è´¥: {e}")
            return False
    
    def validate_result_consistency():
        """éªŒè¯ç»“æœä¸€è‡´æ€§"""
        
        print("ğŸ” ç»“æœä¸€è‡´æ€§éªŒè¯...")
        
        try:
            # åŸç³»ç»Ÿç»“æœï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if 'LayeredCEFRBookSelector' in globals():
                old_selector = LayeredCEFRBookSelector(books_vocab, vocab_levels)
                old_path = old_selector.create_progressive_reading_path()
                old_books = old_path.get("total_books", [])
            else:
                print("âš ï¸ åŸç³»ç»Ÿä¸å¯ç”¨ï¼Œè·³è¿‡ä¸€è‡´æ€§éªŒè¯")
                return True
            
            # æ–°ç³»ç»Ÿç»“æœ
            config = VocabularyLevelConfig.create_cefr_config()
            builder = LayeredVocabularyPathBuilder(books_vocab, vocab_levels, config)
            new_path = builder.create_reading_path()
            new_books = new_path.total_books
            
            # æ¯”è¾ƒç»“æœ
            overlap = set(old_books) & set(new_books)
            consistency_ratio = len(overlap) / max(len(old_books), len(new_books))
            
            print(f"ğŸ“Š ç»“æœä¸€è‡´æ€§: {consistency_ratio:.1%}")
            
            if consistency_ratio >= 0.8:
                print("âœ… ç»“æœé«˜åº¦ä¸€è‡´")
                return True
            elif consistency_ratio >= 0.6:
                print("âš ï¸ ç»“æœåŸºæœ¬ä¸€è‡´ï¼Œå­˜åœ¨ä¼˜åŒ–")
                return True
            else:
                print("âŒ ç»“æœå·®å¼‚è¾ƒå¤§ï¼Œéœ€è¦è°ƒæŸ¥")
                return False
                
        except Exception as e:
            print(f"âŒ ä¸€è‡´æ€§éªŒè¯å¤±è´¥: {e}")
            return False
    
    def run_full_validation():
        """è¿è¡Œå®Œæ•´éªŒè¯"""
        
        print("ğŸš€ å¼€å§‹å®Œæ•´å…¼å®¹æ€§éªŒè¯...\n")
        
        api_ok = validate_api_compatibility()
        consistency_ok = validate_result_consistency()
        
        print("\nğŸ“‹ éªŒè¯æŠ¥å‘Š:")
        print(f"  APIå…¼å®¹æ€§: {'âœ… é€šè¿‡' if api_ok else 'âŒ å¤±è´¥'}")
        print(f"  ç»“æœä¸€è‡´æ€§: {'âœ… é€šè¿‡' if consistency_ok else 'âŒ å¤±è´¥'}")
        
        if api_ok and consistency_ok:
            print("\nğŸ‰ è¿ç§»éªŒè¯æˆåŠŸï¼å¯ä»¥å®‰å…¨ä½¿ç”¨æ–°ç³»ç»Ÿ")
        else:
            print("\nâš ï¸ å‘ç°é—®é¢˜ï¼Œå»ºè®®è¯¦ç»†æ£€æŸ¥è¿ç§»è¿‡ç¨‹")
        
        return api_ok and consistency_ok
    
    return run_full_validation
```

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”

### è¿ç§»å‰åæ€§èƒ½æµ‹è¯•

```python
def performance_comparison():
    """è¿ç§»å‰åæ€§èƒ½å¯¹æ¯”"""
    
    import time
    
    print("â±ï¸ æ€§èƒ½å¯¹æ¯”æµ‹è¯•...")
    
    # æµ‹è¯•æ•°æ®å‡†å¤‡
    test_books = dict(list(books_vocab.items())[:100])  # ä½¿ç”¨100æœ¬ä¹¦æµ‹è¯•
    
    # åŸç³»ç»Ÿæ€§èƒ½æµ‹è¯•
    if 'LayeredCEFRBookSelector' in globals():
        start_time = time.time()
        
        old_selector = LayeredCEFRBookSelector(test_books, vocab_levels)
        old_path = old_selector.create_progressive_reading_path()
        
        old_time = time.time() - start_time
        old_books_count = len(old_path.get("total_books", []))
    else:
        old_time = None
        old_books_count = None
    
    # æ–°ç³»ç»Ÿæ€§èƒ½æµ‹è¯•
    start_time = time.time()
    
    config = VocabularyLevelConfig.create_cefr_config()
    builder = LayeredVocabularyPathBuilder(test_books, vocab_levels, config)
    new_path = builder.create_reading_path()
    
    new_time = time.time() - start_time
    new_books_count = len(new_path.total_books)
    
    # ç»“æœå¯¹æ¯”
    print(f"\nğŸ“Š æ€§èƒ½å¯¹æ¯”ç»“æœ:")
    if old_time is not None:
        print(f"  åŸç³»ç»Ÿè€—æ—¶: {old_time:.2f}ç§’")
        print(f"  æ–°ç³»ç»Ÿè€—æ—¶: {new_time:.2f}ç§’")
        
        if new_time < old_time:
            improvement = (old_time - new_time) / old_time * 100
            print(f"  ğŸš€ æ€§èƒ½æå‡: {improvement:.1f}%")
        else:
            degradation = (new_time - old_time) / old_time * 100
            print(f"  âš ï¸ æ€§èƒ½ä¸‹é™: {degradation:.1f}%")
        
        print(f"  åŸç³»ç»Ÿé€‰ä¹¦: {old_books_count}æœ¬")
        print(f"  æ–°ç³»ç»Ÿé€‰ä¹¦: {new_books_count}æœ¬")
    else:
        print(f"  æ–°ç³»ç»Ÿè€—æ—¶: {new_time:.2f}ç§’")
        print(f"  æ–°ç³»ç»Ÿé€‰ä¹¦: {new_books_count}æœ¬")
```

## ğŸ¯ è¿ç§»æœ€ä½³å®è·µ

### 1. æ¸è¿›å¼è¿ç§»ç­–ç•¥

```python
# é˜¶æ®µ1ï¼šä¿æŒç°æœ‰åŠŸèƒ½
config = VocabularyLevelConfig.create_cefr_config()
builder = LayeredVocabularyPathBuilder(books_vocab, vocab_levels, config)

# é˜¶æ®µ2ï¼šå¯ç”¨æ–°ç‰¹æ€§
alternative_paths = builder.get_alternative_paths()

# é˜¶æ®µ3ï¼šä¼˜åŒ–å‚æ•°
custom_params = PathGenerationParameters.create_conservative_defaults(config.levels)
optimized_path = builder.create_reading_path(custom_params)
```

### 2. é”™è¯¯å¤„ç†å’Œå›é€€

```python
def safe_migration_wrapper(books_vocab, vocab_levels):
    """å®‰å…¨è¿ç§»åŒ…è£…å™¨"""
    
    try:
        # å°è¯•ä½¿ç”¨æ–°ç³»ç»Ÿ
        config = VocabularyLevelConfig.create_cefr_config()
        builder = LayeredVocabularyPathBuilder(books_vocab, vocab_levels, config)
        path = builder.create_reading_path()
        
        print("âœ… ä½¿ç”¨æ–°ç³»ç»Ÿç”Ÿæˆè·¯å¾„")
        return builder, path
        
    except Exception as e:
        print(f"âš ï¸ æ–°ç³»ç»Ÿå‡ºé”™ï¼Œå›é€€åˆ°åŸç³»ç»Ÿ: {e}")
        
        # å›é€€åˆ°åŸç³»ç»Ÿ
        if 'LayeredCEFRBookSelector' in globals():
            old_selector = LayeredCEFRBookSelector(books_vocab, vocab_levels)
            old_path = old_selector.create_progressive_reading_path()
            
            print("ğŸ”„ å·²å›é€€åˆ°åŸç³»ç»Ÿ")
            return old_selector, old_path
        else:
            raise Exception("æ–°æ—§ç³»ç»Ÿéƒ½ä¸å¯ç”¨")
```

### 3. æµ‹è¯•å’ŒéªŒè¯

```python
def comprehensive_migration_test():
    """ç»¼åˆè¿ç§»æµ‹è¯•"""
    
    print("ğŸ§ª ç»¼åˆè¿ç§»æµ‹è¯•å¼€å§‹...")
    
    # æµ‹è¯•1ï¼šåŸºæœ¬åŠŸèƒ½
    print("\n1ï¸âƒ£ åŸºæœ¬åŠŸèƒ½æµ‹è¯•...")
    config = VocabularyLevelConfig.create_cefr_config()
    builder = LayeredVocabularyPathBuilder(books_vocab, vocab_levels, config)
    path = builder.create_reading_path()
    
    assert len(path.total_books) > 0, "æ²¡æœ‰ç”Ÿæˆä»»ä½•ä¹¦ç±"
    print("âœ… åŸºæœ¬åŠŸèƒ½æ­£å¸¸")
    
    # æµ‹è¯•2ï¼šæ•°æ®ä¸€è‡´æ€§
    print("\n2ï¸âƒ£ æ•°æ®ä¸€è‡´æ€§æµ‹è¯•...")
    book_stats = builder.get_book_statistics(path.total_books[0])
    assert book_stats is not None, "ä¹¦ç±ç»Ÿè®¡æ•°æ®ä¸ºç©º"
    print("âœ… æ•°æ®ä¸€è‡´æ€§æ­£å¸¸")
    
    # æµ‹è¯•3ï¼šé…ç½®çµæ´»æ€§
    print("\n3ï¸âƒ£ é…ç½®çµæ´»æ€§æµ‹è¯•...")
    custom_config = config.model_copy(update={
        "weights": {"A1": 2.0, "A2": 1.5, "B1": 1.0, "B2": 0.8, "C1": 0.6}
    })
    custom_builder = LayeredVocabularyPathBuilder(books_vocab, vocab_levels, custom_config)
    custom_path = custom_builder.create_reading_path()
    print("âœ… é…ç½®çµæ´»æ€§æ­£å¸¸")
    
    # æµ‹è¯•4ï¼šæ€§èƒ½æµ‹è¯•
    print("\n4ï¸âƒ£ æ€§èƒ½æµ‹è¯•...")
    start_time = time.time()
    for _ in range(5):
        test_path = builder.create_reading_path()
    end_time = time.time()
    
    avg_time = (end_time - start_time) / 5
    print(f"âœ… å¹³å‡ç”Ÿæˆæ—¶é—´: {avg_time:.2f}ç§’")
    
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼è¿ç§»æˆåŠŸ")
```

## ğŸ”„ ä¸‹ä¸€æ­¥é¢„å‘Š

è¿ç§»åªæ˜¯å¼€å§‹ï¼ŒçœŸæ­£çš„å¨åŠ›åœ¨äºå®šåˆ¶ã€‚åœ¨ä¸‹ä¸€ç« **é«˜çº§å®šåˆ¶ä¸æ‰©å±•**ä¸­ï¼Œæˆ‘ä»¬å°†å­¦ä¹ ï¼š

- å¦‚ä½•è®¾è®¡è‡ªå®šä¹‰è¿›å±•ç±»å‹
- æ‰©å±•ä¹¦ç±åˆ†æç»´åº¦çš„æ–¹æ³•
- å®ç°ä¸“ç”¨è¯„åˆ†ç®—æ³•
- ä¸å¤–éƒ¨ç³»ç»Ÿçš„æ·±åº¦é›†æˆ

**æ€è€ƒé¢˜**ï¼š

1. ä½ çš„é¡¹ç›®ä¸­å“ªäº›éƒ¨åˆ†æœ€é€‚åˆæ¸è¿›å¼è¿ç§»ï¼Ÿ
2. å¦‚ä½•è®¾è®¡æµ‹è¯•ç”¨ä¾‹æ¥éªŒè¯è¿ç§»çš„æ­£ç¡®æ€§ï¼Ÿ
3. è¿ç§»è¿‡ç¨‹ä¸­å¦‚ä½•å¹³è¡¡æ–°åŠŸèƒ½å’Œç¨³å®šæ€§ï¼Ÿ

å‡†å¤‡å¥½è§£é”ç³»ç»Ÿçš„æ— é™å¯èƒ½äº†å—ï¼Ÿ

---

> "Migration is not just about moving from old to new; it's about carrying forward the wisdom of the past while embracing the possibilities of the future."
> "è¿ç§»ä¸ä»…ä»…æ˜¯ä»æ—§åˆ°æ–°çš„è½¬æ¢ï¼›å®ƒæ˜¯åœ¨æ‹¥æŠ±æœªæ¥å¯èƒ½æ€§çš„åŒæ—¶ï¼Œä¼ æ‰¿è¿‡å»çš„æ™ºæ…§ã€‚"
